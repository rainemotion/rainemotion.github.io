<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>只是无聊而已</title>
  
  <subtitle>我想不开</subtitle>
  <link href="http://rainemotion.github.io/atom.xml" rel="self"/>
  
  <link href="http://rainemotion.github.io/"/>
  <updated>2025-11-05T13:22:27.336Z</updated>
  <id>http://rainemotion.github.io/</id>
  
  <author>
    <name>雨</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>统计学习方法概论</title>
    <link href="http://rainemotion.github.io/2025/11/05/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%86%B5/"/>
    <id>http://rainemotion.github.io/2025/11/05/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%86%B5/</id>
    <published>2025-11-05T13:22:45.036Z</published>
    <updated>2025-11-05T13:22:27.336Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一-统计学习方法概论"><a href="#一-统计学习方法概论" class="headerlink" title="一.  统计学习方法概论"></a>一.  <strong>统计学习方法概论</strong></h1><p>​         主要是对统计学习这门学科进行宏观的介绍，包括其定义、研究对象、方法、分类以及在人工智能中的地位。理解这一章有助于我们建立对整个统计学习框架的认识。</p><h3 id="核心内容概览："><a href="#核心内容概览：" class="headerlink" title="核心内容概览："></a>核心内容概览：</h3><ol><li><strong>统计学习的定义与特点</strong></li><li><strong>统计学习的分类</strong></li><li><strong>统计学习三要素：模型、策略、算法</strong></li><li><strong>模型评估与模型选择</strong></li><li><strong>正则化与交叉验证</strong></li><li><strong>泛化能力</strong></li><li><strong>生成模型与判别模型</strong></li><li><strong>统计学习方法在人工智能、机器学习、数据挖掘中的关系</strong></li></ol><h3 id="详细讲解与学习建议："><a href="#详细讲解与学习建议：" class="headerlink" title="详细讲解与学习建议："></a>详细讲解与学习建议：</h3><h4 id="1-统计学习的定义与特点"><a href="#1-统计学习的定义与特点" class="headerlink" title="1. 统计学习的定义与特点"></a>1. 统计学习的定义与特点</h4><ul><li><p><strong>定义</strong>：统计学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。它的主要特点是：</p><ul><li><strong>以数据为中心</strong>：处理的是各种类型的数据。</li><li><strong>以模型为方法</strong>：通过构建模型来学习数据中的规律。</li><li><strong>以预测与分析为目的</strong>：利用模型进行预测、分类、聚类等。</li><li><strong>是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科</strong>。</li></ul></li><li><p><strong>学习建议</strong>：理解“模型”、“预测”、“分析”这几个关键词。</p></li></ul><h4 id="2-统计学习的分类"><a href="#2-统计学习的分类" class="headerlink" title="2. 统计学习的分类"></a>2. 统计学习的分类</h4><p>统计学习方法可以从不同的角度进行分类：</p><ul><li><p><strong>根据数据类型</strong>：</p><ul><li>**监督学习 (Supervised Learning)**：数据有标记（输入和输出），目标是学习一个从输入到输出的映射。例如：分类（输出是离散值）、回归（输出是连续值）。</li><li>**无监督学习 (Unsupervised Learning)**：数据没有标记，目标是发现数据内在的结构或模式。例如：聚类、降维。</li><li>**半监督学习 (Semi-supervised Learning)**：部分数据有标记，部分无标记。</li><li>**强化学习 (Reinforcement Learning)**：智能体与环境交互，通过试错学习最优策略。</li></ul></li><li><p><strong>根据模型类型</strong>：</p><ul><li>**生成模型 (Generative Model)**：学习联合概率分布 $P(X, Y)$，然后根据贝叶斯公式计算 $P(Y|X)$ 进行预测。可以用于生成数据。</li><li>**判别模型 (Discriminative Model)**：直接学习条件概率分布 $P(Y|X)$ 或者决策函数 $f(X)$。</li></ul></li><li><p><strong>根据学习方法</strong>：</p><ul><li><strong>贝叶斯学习</strong></li><li><strong>核方法</strong></li><li><strong>支持向量机</strong></li><li><strong>神经网络</strong> 等</li></ul></li><li><p><strong>学习建议</strong>：重点掌握监督学习和无监督学习的定义和常见任务，以及生成模型和判别模型的区别，这是后续章节的基础。</p></li></ul><h4 id="3-统计学习三要素：模型、策略、算法"><a href="#3-统计学习三要素：模型、策略、算法" class="headerlink" title="3. 统计学习三要素：模型、策略、算法"></a>3. 统计学习三要素：模型、策略、算法</h4><p>这是统计学习方法的核心框架，任何一个统计学习方法都包含这三部分：</p><ul><li><p>**模型 (Model)**：</p><ul><li><strong>定义</strong>：所要学习的条件概率分布或决策函数。</li><li><strong>表示</strong>：可以是函数集合 ${f| Y &#x3D; f_\theta(X), \theta \in \mathbb{R}^n}$ 或条件概率集合 ${P| P_\theta(Y|X), \theta \in \mathbb{R}^n}$。</li><li><strong>选择</strong>：模型的选择决定了学习的范围和复杂度。</li></ul></li><li><p>**策略 (Strategy)**：</p><ul><li><p><strong>定义</strong>：评估模型好坏的标准。</p></li><li><p>**损失函数 (Loss Function) &#x2F; 代价函数 (Cost Function)**：度量模型预测值 $f(X)$ 与真实值 $Y$ 之间不一致的程度，损失函数值越小，模型越好。常见的有：</p><ul><li><strong>0-1 损失函数</strong>：<br>$L(Y, f(X)) &#x3D; \begin{cases} 1, &amp; Y \neq f(X) \ 0, &amp; Y &#x3D; f(X) \end{cases}$</li><li>**平方损失函数 (Squared Loss Function)**：<br>$L(Y, f(X)) &#x3D; (Y - f(X))^2$</li><li>**绝对损失函数 (Absolute Loss Function)**：<br>$L(Y, f(X)) &#x3D; |Y - f(X)|$</li><li><strong>对数损失函数 (Log-likelihood Loss Function) 或对数似然损失函数</strong>：<br>$L(Y, P(Y|X)) &#x3D; -\log P(Y|X)$</li></ul></li><li><p>**风险函数 (Risk Function) &#x2F; 期望损失 (Expected Loss)**：损失函数的期望，是理论上模型关于联合分布的平均损失。<br>$R_{exp}(f) &#x3D; E_P[L(Y, f(X))] &#x3D; \int_{X \times Y} L(y, f(x)) P(x, y) dx dy$<br>由于 $P(X, Y)$ 未知，所以无法直接计算。</p></li><li><p>**经验风险 (Empirical Risk) &#x2F; 经验损失 (Empirical Loss)**：在训练数据集上的平均损失。<br>$R_{emp}(f) &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N L(y_i, f(x_i))$</p></li><li><p>**结构风险 (Structural Risk)**：经验风险 + 正则化项，为了防止过拟合。<br>$R_{srm}(f) &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N L(y_i, f(x_i)) + \lambda J(f)$<br>其中 $J(f)$ 为模型的复杂度，$\lambda \ge 0$ 为正则化系数。</p></li><li><p><strong>学习策略</strong>：最小化经验风险或结构风险。</p></li></ul></li><li><p>**算法 (Algorithm)**：</p><ul><li><strong>定义</strong>：学习模型的具体计算方法。</li><li><strong>作用</strong>：求解最优化问题，即在给定的模型空间中，找到使损失函数或结构风险函数最小的模型参数。</li><li><strong>例子</strong>：梯度下降、牛顿法、EM 算法等。</li></ul></li><li><p><strong>学习建议</strong>：这三要素是贯穿全书的主线，务必理解它们各自的含义以及它们之间的关系。特别要区分损失函数、经验风险和结构风险。</p></li></ul><h4 id="4-模型评估与模型选择"><a href="#4-模型评估与模型选择" class="headerlink" title="4. 模型评估与模型选择"></a>4. 模型评估与模型选择</h4><ul><li><p><strong>目的</strong>：选择最合适的模型。</p></li><li><p>**训练误差 (Training Error)**：模型在训练集上的误差。<br>$R_{train}(f) &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N L(y_i, f(x_i))$</p></li><li><p>**测试误差 (Test Error)**：模型在测试集上的误差。<br>$R_{test}(f) &#x3D; \frac{1}{N’} \sum_{j&#x3D;1}^{N’} L(y_j, f(x_j))$<br>其中 $N’$ 是测试集样本容量。测试误差反映了模型的泛化能力。</p></li><li><p>**过拟合 (Overfitting)**：模型对训练数据学习得“太好”，以至于把训练数据的一些噪声和特有规律也学进去了，导致在未知数据上表现很差。表现为训练误差很小，但测试误差很大。</p></li><li><p>**欠拟合 (Underfitting)**：模型没有很好地学习训练数据中的模式，导致训练误差和测试误差都很大。</p></li><li><p><strong>学习建议</strong>：理解训练误差和测试误差的区别，以及过拟合和欠拟合的现象及其原因。</p></li></ul><h4 id="5-正则化与交叉验证"><a href="#5-正则化与交叉验证" class="headerlink" title="5. 正则化与交叉验证"></a>5. 正则化与交叉验证</h4><ul><li><p>**正则化 (Regularization)**：</p><ul><li><strong>目的</strong>：防止过拟合，提高模型的泛化能力。</li><li><strong>方法</strong>：在经验风险的基础上增加一个正则化项（惩罚项），通常是模型复杂度的函数。<br>$\min_f \frac{1}{N} \sum_{i&#x3D;1}^N L(y_i, f(x_i)) + \lambda J(f)$<br>其中 $J(f)$ 可以是模型参数的 L1 范数（Lasso）或 L2 范数（Ridge）。正则化项通常倾向于选择更简单的模型。</li><li><strong>作用</strong>：对模型参数进行约束，使其不要过大，从而降低模型的复杂度。</li></ul></li><li><p>**交叉验证 (Cross Validation)**：</p><ul><li><p><strong>目的</strong>：评估模型的泛化能力，进行模型选择。</p></li><li><p><strong>方法</strong>：将数据集划分为训练集和测试集。常见的有：</p><ul><li><strong>简单交叉验证</strong>：随机分成训练集和测试集。</li><li>**S 折交叉验证 (K-Fold Cross Validation)**：将数据分成 S 份，每次用 S-1 份做训练，1 份做测试，重复 S 次，取 S 次测试结果的平均值作为评估。</li><li>**留一交叉验证 (Leave-One-Out Cross Validation)**：S 折交叉验证的特殊情况，S 等于样本总数。</li></ul></li></ul></li><li><p><strong>学习建议</strong>：正则化和交叉验证是实践中非常重要的技术，要理解它们为什么有效以及如何应用。</p></li></ul><h4 id="6-泛化能力"><a href="#6-泛化能力" class="headerlink" title="6. 泛化能力"></a>6. 泛化能力</h4><ul><li><p><strong>定义</strong>：学习方法对未知数据的预测能力。</p></li><li><p>**泛化误差 (Generalization Error)**：模型关于联合分布 $P$ 的期望损失。<br>$R_{exp}(f) &#x3D; E_P[L(Y, f(X))]$</p></li><li><p><strong>泛化误差上界</strong>：对泛化误差的估计，在某些条件下可以导出。</p></li><li><p><strong>学习建议</strong>：理解泛化能力是统计学习追求的最终目标。</p></li></ul><h4 id="7-生成模型与判别模型"><a href="#7-生成模型与判别模型" class="headerlink" title="7. 生成模型与判别模型"></a>7. 生成模型与判别模型</h4><p>这是前面提过的分类，这里再强调一下它们的区别：</p><ul><li><p><strong>生成模型</strong>：</p><ul><li>学习 $P(X, Y)$（联合概率分布）。</li><li>通过 $P(Y|X) &#x3D; P(X, Y) &#x2F; P(X)$ 进行预测。</li><li>优点：可以反映数据内在的统计特性，学习到 $P(X)$ 可以用于数据生成，在数据不完整时依然可用。</li><li>缺点：学习的计算量大，当模型假设不正确时表现会差。</li><li>常见例子：朴素贝叶斯、隐马尔可夫模型、高斯混合模型。</li></ul></li><li><p><strong>判别模型</strong>：</p><ul><li>直接学习 $P(Y|X)$（条件概率分布）或决策函数 $f(X)$。</li><li>优点：直接学习预测，准确率通常更高，计算量小，对数据分布没有假设。</li><li>缺点：不能反映数据的内在性质，不能用于生成数据。</li><li>常见例子：K 近邻、感知机、决策树、逻辑斯谛回归、支持向量机、提升方法、神经网络。</li></ul></li><li><p><strong>学习建议</strong>：这是非常重要的概念，区分它们对于理解不同算法的适用场景和原理至关重要。</p></li></ul><h4 id="8-统计学习方法在人工智能、机器学习、数据挖掘中的关系"><a href="#8-统计学习方法在人工智能、机器学习、数据挖掘中的关系" class="headerlink" title="8. 统计学习方法在人工智能、机器学习、数据挖掘中的关系"></a>8. 统计学习方法在人工智能、机器学习、数据挖掘中的关系</h4><ul><li><p>**人工智能 (AI)**：最广泛的领域，目的是使机器像人一样智能地思考和行动。</p></li><li><p>**机器学习 (Machine Learning)**：人工智能的一个子领域，研究如何让计算机从数据中学习，而无需明确编程。</p></li><li><p>**统计学习 (Statistical Learning)**：机器学习的一个重要组成部分，主要通过概率统计方法进行学习。</p></li><li><p>**数据挖掘 (Data Mining)**：从大量数据中发现有用的模式和知识的过程，通常会用到统计学习和机器学习的方法。</p></li><li><p><strong>学习建议</strong>：理解这些概念之间的包含关系和侧重点，有助于建立对整个技术生态的认知。</p></li></ul><h3 id="学习方法建议："><a href="#学习方法建议：" class="headerlink" title="学习方法建议："></a>学习方法建议：</h3><ol><li><strong>通读一遍</strong>：先快速通读全章，对整体内容有个初步印象。</li><li><strong>细读重点</strong>：对“三要素”、“模型评估与选择”、“过拟合与欠拟合”、“正则化与交叉验证”、“生成模型与判别模型”等核心概念进行精读，确保理解它们的定义和作用。</li><li><strong>做笔记</strong>：将关键概念、公式、图表整理成自己的笔记。</li><li><strong>举例思考</strong>：尝试用生活中的例子或自己熟悉的简单场景来解释这些概念，加深理解。例如，如何用“三要素”来描述一个简单的“判断苹果是红的还是绿的”模型。</li><li><strong>阅读习题</strong>：书后的习题也是很好的巩固材料，可以尝试思考或解答。</li><li><strong>联系后续章节</strong>：第一章是纲领性的，它为后续的具体算法铺垫了理论基础。在学习后续章节时，要时不时回顾第一章的框架，将具体算法的细节与第一章的宏观概念联系起来。</li></ol><h1 id="二-统计学习三要素"><a href="#二-统计学习三要素" class="headerlink" title="二.统计学习三要素"></a>二.统计学习三要素</h1><h3 id="统计学习三要素：模型、策略、算法"><a href="#统计学习三要素：模型、策略、算法" class="headerlink" title="统计学习三要素：模型、策略、算法"></a>统计学习三要素：模型、策略、算法</h3><p>每一个具体的统计学习方法都包含模型、策略和算法这三个要素。它们分别回答了以下问题：</p><ol><li><strong>模型（Model）</strong>：学习什么样的函数？（即我们要选择什么样的函数集合或概率分布集合作为学习的目标？）</li><li><strong>策略（Strategy）</strong>：用什么标准来衡量学习的好坏？（即如何定义一个损失函数，并在此基础上形成优化目标？）</li><li><strong>算法（Algorithm）</strong>：如何找到最好的那个函数？（即如何高效地求解优化问题，找到最佳的模型参数？）</li></ol><p>下面我们逐一详细展开，并结合一个简单的例子进行说明。</p><hr><h4 id="1-模型-Model"><a href="#1-模型-Model" class="headerlink" title="1. 模型 (Model)"></a>1. 模型 (Model)</h4><p><strong>定义：</strong> 统计学习中所谓的“模型”，指的是我们要学习的 <strong>条件概率分布</strong> $P(Y|X)$ 或 <strong>决策函数</strong> $f(X)$。它实际上是一个从输入空间到输出空间的映射，代表了我们希望从数据中发现的规律。</p><p><strong>理解：</strong></p><ul><li><p><strong>函数集合或概率分布集合：</strong> 模型不是一个单一的函数，而是一个包含多个可能函数的集合。我们希望在这个集合中找到一个“最好”的函数。这个集合通常由特定的数学形式（如线性函数、多项式函数、神经网络）和待定参数决定。</p></li><li><p><strong>参数化模型：</strong> 大多数统计学习模型都是参数化的。这意味着我们可以通过调整一些参数来改变模型的具体形式。例如，一个线性模型 $f(x) &#x3D; wx + b$ 的参数就是 $w$ 和 $b$。</p></li><li><p><strong>模型复杂性：</strong> 模型集合的大小和复杂性对学习效果有重要影响。</p><ul><li><strong>简单的模型</strong>（如线性函数）可能无法捕捉数据中的复杂模式，导致欠拟合。</li><li><strong>复杂的模型</strong>（如高阶多项式、深度神经网络）有能力捕捉复杂模式，但也更容易过拟合。</li></ul></li></ul><p><strong>表示形式：</strong></p><ul><li><strong>决策函数集合：</strong> ${f | Y &#x3D; f_\theta(X), \theta \in \mathbb{R}^n}$，其中 $f_\theta$ 表示由参数 $\theta$ 决定的函数。</li><li><strong>条件概率分布集合：</strong> ${P | P_\theta(Y|X), \theta \in \mathbb{R}^n}$，其中 $P_\theta$ 表示由参数 $\theta$ 决定的条件概率分布。</li></ul><hr><h4 id="2-策略-Strategy"><a href="#2-策略-Strategy" class="headerlink" title="2. 策略 (Strategy)"></a>2. 策略 (Strategy)</h4><p><strong>定义：</strong> 策略是评价模型好坏的标准。它告诉我们，在给定的训练数据上，一个模型（或其参数）表现得有多好。这个标准通常通过 <strong>损失函数</strong> 和 <strong>风险函数</strong> 来量化。</p><p><strong>理解：</strong></p><ul><li><p><strong>损失函数（Loss Function） &#x2F; 代价函数（Cost Function）：</strong> 度量模型一次预测结果（对一个样本）与真实值之间不一致的程度。损失函数值越小，模型对这个样本的预测效果越好。它是非负实值函数。</p><ul><li><p><strong>常见损失函数：</strong></p><ol><li>**0-1 损失函数 (0-1 Loss)**：<br>$L(Y, f(X)) &#x3D; \begin{cases} 1, &amp; Y \neq f(X) \ 0, &amp; Y &#x3D; f(X) \end{cases}$<br>如果预测值与真实值不同，则损失为 1；否则为 0。常用于分类问题，但由于不连续，不易优化。</li><li>**平方损失函数 (Squared Loss Function)**：<br>$L(Y, f(X)) &#x3D; (Y - f(X))^2$<br>预测值与真实值差值的平方。常用于回归问题，对异常值敏感。</li><li>**绝对损失函数 (Absolute Loss Function)**：<br>$L(Y, f(X)) &#x3D; |Y - f(X)|$<br>预测值与真实值差值的绝对值。常用于回归问题，相比平方损失对异常值不那么敏感。</li><li><strong>对数损失函数 (Log-likelihood Loss Function) &#x2F; 对数似然损失函数</strong>：<br>$L(Y, P(Y|X)) &#x3D; -\log P(Y|X)$<br>当模型输出的是概率时使用。例如，在二分类中，如果真实标签是 $y$ (0 或 1)，预测概率是 $p$，那么损失可以是 $-\log p$ (如果 $y&#x3D;1$) 或 $-\log (1-p)$ (如果 $y&#x3D;0$)。它鼓励模型对真实标签给出更高的概率预测。</li></ol></li></ul></li><li><p><strong>风险函数（Risk Function）&#x2F; 期望损失（Expected Loss）：</strong></p><ul><li><strong>定义：</strong> 理论上模型关于 <strong>联合概率分布</strong> $P(X, Y)$ 的平均损失。它反映了模型在所有可能数据上的平均表现。<br>$R_{exp}(f) &#x3D; E_P[L(Y, f(X))] &#x3D; \int_{X \times Y} L(y, f(x)) P(x, y) dx dy$</li><li><strong>问题：</strong> 联合概率分布 $P(X, Y)$ 是未知的，所以我们无法直接计算并最小化期望损失。</li></ul></li><li><p><strong>经验风险（Empirical Risk）&#x2F; 经验损失（Empirical Loss）：</strong></p><ul><li><strong>定义：</strong> 模型在 <strong>训练数据集</strong> 上的平均损失。它是对期望风险的近似。<br>$R_{emp}(f) &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N L(y_i, f(x_i))$</li><li><strong>问题：</strong> 经验风险最小化容易导致 <strong>过拟合</strong>。当训练数据量很小或者模型过于复杂时，模型可能完美地记住训练数据，但在新的数据上表现很差。</li></ul></li><li><p><strong>结构风险（Structural Risk）：</strong></p><ul><li><p><strong>定义：</strong> 为了防止过拟合，在经验风险的基础上加上一个 <strong>正则化项 (Regularizer)</strong> 或 **惩罚项 (Penalty Term)**。<br>$R_{srm}(f) &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N L(y_i, f(x_i)) + \lambda J(f)$<br>其中：</p><ul><li><p>$\frac{1}{N} \sum_{i&#x3D;1}^N L(y_i, f(x_i))$ 是经验风险，衡量模型对训练数据的拟合程度。</p></li><li><p>$J(f)$ 是正则化项，衡量模型的复杂度。模型越复杂，$J(f)$ 值越大。常见的有：</p><ul><li>L1 正则化（Lasso）：$\sum |\theta_j|$</li><li>L2 正则化（Ridge）：$\sum \theta_j^2$</li></ul></li><li><p>$\lambda \ge 0$ 是正则化系数，用于平衡经验风险和模型复杂度。$\lambda$ 越大，对模型复杂度的惩罚越大，模型倾向于越简单。</p></li></ul></li><li><p><strong>作用：</strong> 结构风险最小化是比经验风险最小化更优的策略，它在经验风险和模型复杂度之间进行权衡，以提高模型的泛化能力。</p></li></ul></li></ul><p><strong>学习策略：</strong> 统计学习的最终目标是选择模型，使其 <strong>期望风险最小化</strong>。但由于期望风险不可知，实际中通常采用 <strong>经验风险最小化</strong> 或 <strong>结构风险最小化</strong> 策略。</p><hr><h4 id="3-算法-Algorithm"><a href="#3-算法-Algorithm" class="headerlink" title="3. 算法 (Algorithm)"></a>3. 算法 (Algorithm)</h4><p><strong>定义：</strong> 算法是学习模型的具体计算方法，即如何找到最优模型参数的计算过程。它负责求解策略中定义的优化问题。</p><p><strong>理解：</strong></p><ul><li><p><strong>优化问题：</strong> 策略确定后，我们就得到了一个明确的优化目标（例如，最小化经验风险或结构风险）。算法就是解决这个优化问题的工具。</p></li><li><p><strong>计算效率：</strong> 算法的效率至关重要，尤其是在处理大规模数据和复杂模型时。</p></li><li><p><strong>常见优化算法：</strong></p><ul><li>**梯度下降 (Gradient Descent)**：通过迭代地沿着损失函数梯度的反方向更新参数。</li><li>**随机梯度下降 (Stochastic Gradient Descent, SGD)**：每次只用一个（或一小批）样本来估计梯度并更新参数，适用于大数据集。</li><li>**牛顿法 (Newton’s Method)**：利用二阶导数信息（Hessian 矩阵）加速收敛，但计算量大。</li><li>**拟牛顿法 (Quasi-Newton Methods)**：用近似的二阶导数信息，如 L-BFGS。</li><li>**EM 算法 (Expectation-Maximization Algorithm)**：当模型中含有隐变量时使用。</li><li>**坐标下降法 (Coordinate Descent)**：每次只优化一个参数，固定其他参数。</li></ul></li></ul><p><strong>算法的选择取决于：</strong></p><ul><li><strong>模型的类型：</strong> 不同的模型结构（如线性模型、非线性模型、神经网络）可能需要不同的优化算法。</li><li><strong>损失函数的类型：</strong> 损失函数是否可导、凸性等性质会影响算法的选择。</li><li><strong>数据的规模：</strong> 大规模数据可能需要批处理或在线学习算法。</li><li><strong>计算资源：</strong> 可用的内存、计算能力。</li></ul><hr><h3 id="例子说明：线性回归模型"><a href="#例子说明：线性回归模型" class="headerlink" title="例子说明：线性回归模型"></a>例子说明：线性回归模型</h3><p>我们以最简单的 <strong>线性回归</strong> 为例，来具体说明这三要素。</p><p><strong>任务：</strong> 预测一套房子的价格，给定其面积大小。</p><p><strong>训练数据：</strong> 一系列房子面积 $x_i$ 和对应的价格 $y_i$。</p><h4 id="1-模型-Model-1"><a href="#1-模型-Model-1" class="headerlink" title="1. 模型 (Model)"></a>1. 模型 (Model)</h4><ul><li><p><strong>选择的模型类型：</strong> 我们假设房子的价格与面积之间存在线性关系。</p></li><li><p><strong>模型表达式：</strong> 我们选择一个线性函数作为我们的模型。<br>$f(x) &#x3D; w x + b$<br>其中：</p><ul><li>$x$ 是输入（房子面积）。</li><li>$f(x)$ 是预测的输出（房子价格）。</li><li>$w$ 是斜率（权重）。</li><li>$b$ 是截距（偏置）。</li></ul></li><li><p><strong>参数：</strong> 模型的参数是 $\theta &#x3D; (w, b)$。</p></li><li><p><strong>模型集合：</strong> 我们可以认为我们的模型是所有可能的线性函数组成的集合，通过调整 $w$ 和 $b$ 来选择其中一个。</p></li></ul><h4 id="2-策略-Strategy-1"><a href="#2-策略-Strategy-1" class="headerlink" title="2. 策略 (Strategy)"></a>2. 策略 (Strategy)</h4><ul><li><strong>损失函数：</strong> 对于回归问题，我们通常选择 <strong>平方损失函数</strong> 来度量单个预测的误差。<br>$L(y_i, f(x_i)) &#x3D; (y_i - f(x_i))^2 &#x3D; (y_i - (w x_i + b))^2$</li><li><strong>优化目标（经验风险最小化）：</strong> 我们希望找到参数 $(w, b)$，使得模型在所有训练数据上的平均损失最小。这就是经验风险。<br>$\min_{w, b} R_{emp}(w, b) &#x3D; \min_{w, b} \frac{1}{N} \sum_{i&#x3D;1}^N (y_i - (w x_i + b))^2$<br>（这里为了简化，我们暂时不考虑结构风险，即不加正则化项。如果加上正则化项，例如 L2 正则化，则优化目标变为结构风险最小化：<br>$\min_{w, b} \frac{1}{N} \sum_{i&#x3D;1}^N (y_i - (w x_i + b))^2 + \lambda (w^2 + b^2)$<br>）</li></ul><h4 id="3-算法-Algorithm-1"><a href="#3-算法-Algorithm-1" class="headerlink" title="3. 算法 (Algorithm)"></a>3. 算法 (Algorithm)</h4><ul><li><p><strong>如何求解？</strong> 我们的目标是找到 $w$ 和 $b$ 的值，使得上述经验风险函数最小。这是一个凸优化问题。</p></li><li><p><strong>选择的算法：</strong> 对于线性回归的平方损失，可以通过两种主要方法求解：</p><ol><li><p>**解析解 (Normal Equation)**：可以直接通过矩阵运算一步到位求得最优的 $w$ 和 $b$。因为平方损失函数是凸的，且可导，其导数为 0 的点就是最小值点。<br>$\theta &#x3D; (X^T X)^{-1} X^T Y$<br>（其中 $\theta &#x3D; \begin{pmatrix} b \ w \end{pmatrix}$，$X$ 是加入常数项 1 的特征矩阵，$Y$ 是目标向量）</p></li><li><p>**迭代解 (Gradient Descent)**：</p><ul><li><p><strong>步骤：</strong></p><ol><li><p>随机初始化 $w$ 和 $b$。</p></li><li><p>重复以下步骤直到收敛：</p><ul><li>计算损失函数对 $w$ 和 $b$ 的偏导数（梯度）。<br>$\frac{\partial R_{emp}}{\partial w} &#x3D; \frac{2}{N} \sum_{i&#x3D;1}^N (w x_i + b - y_i) x_i$<br>$\frac{\partial R_{emp}}{\partial b} &#x3D; \frac{2}{N} \sum_{i&#x3D;1}^N (w x_i + b - y_i)$</li><li>根据梯度更新 $w$ 和 $b$：<br>$w \leftarrow w - \alpha \frac{\partial R_{emp}}{\partial w}$<br>$b \leftarrow b - \alpha \frac{\partial R_{emp}}{\partial b}$<br>其中 $\alpha$ 是学习率，控制每次更新的步长。</li></ul></li></ol></li><li><p><strong>优势：</strong> 当数据量非常大，无法一次性计算矩阵逆时，梯度下降（尤其是其变体如随机梯度下降 SGD）是更可行的选择。</p></li></ul></li></ol></li></ul><p>通过上述步骤，我们就找到了一个最优的线性模型 $f(x) &#x3D; w^* x + b^*$，它可以在训练数据上最小化平方损失，从而对新的房子面积进行价格预测。</p><hr><p><strong>总结：</strong></p><p>“模型、策略、算法”这三要素是理解统计学习方法的基石。</p><ul><li><strong>模型</strong> 决定了我们能学习到什么样的函数形式。</li><li><strong>策略</strong> 定义了我们如何衡量模型的好坏，并设定了优化目标。</li><li><strong>算法</strong> 提供了解决优化问题的具体计算步骤。</li></ul><h1 id="三-无监督学习的三要素"><a href="#三-无监督学习的三要素" class="headerlink" title="三.无监督学习的三要素"></a>三.无监督学习的三要素</h1><p>无监督学习的三要素与监督学习的“模型、策略、算法”框架是共通的，但由于其数据无标签的特性，在具体内容上会有所调整和侧重。</p><p><strong>核心思想：</strong> 无监督学习的目标是发现数据中隐藏的结构、模式或分布，而不是像监督学习那样从输入到输出建立映射关系。因此，其“模型”不再是预测函数，而是数据本身的结构或概率分布；“策略”不再是基于标签的损失，而是基于数据内在一致性或紧密性的度量；“算法”依然是求解最优化问题的过程。</p><p>我们仍然可以使用“模型、策略、算法”的框架来描述无监督学习：</p><h3 id="无监督学习的三要素：模型、策略、算法"><a href="#无监督学习的三要素：模型、策略、算法" class="headerlink" title="无监督学习的三要素：模型、策略、算法"></a>无监督学习的三要素：模型、策略、算法</h3><h4 id="1-模型-Model-2"><a href="#1-模型-Model-2" class="headerlink" title="1. 模型 (Model)"></a>1. 模型 (Model)</h4><p>在无监督学习中，<strong>模型</strong> 通常不再是简单的从输入到输出的映射函数 $f(X)$，而是指：</p><ul><li><strong>数据内在的结构或模式的表示</strong>：例如，聚类算法中的“簇中心”和“簇的形状”，或降维算法中的“低维空间映射”。</li><li><strong>数据的概率分布假设</strong>：例如，高斯混合模型（GMM）假设数据是由多个高斯分布混合生成的。</li><li><strong>数据变换函数</strong>：例如，主成分分析（PCA）中将数据映射到新的正交基上的线性变换。</li></ul><p><strong>理解：</strong></p><ul><li><strong>结构发现：</strong> 无监督学习的模型旨在揭示数据本身固有的结构，例如将数据分成几个有意义的组（聚类），或者找出数据中最主要的变异方向（降维）。</li><li><strong>概率生成：</strong> 有些无监督模型（如 GMM、自编码器）尝试学习数据的潜在生成过程或概率分布，以便能够理解数据是如何产生的，甚至生成类似的新数据。</li><li><strong>参数化与非参数化：</strong> 同监督学习一样，无监督模型也可以是参数化的（如 GMM 的均值、方差）或非参数化的（如 K-Means 的簇中心会随着数据变化）。</li></ul><p><strong>表示形式举例：</strong></p><ul><li><p><strong>聚类：</strong></p><ul><li>K-Means：模型可以看作是 K 个簇的中心 $\mu_1, \mu_2, \dots, \mu_K$。</li><li>层次聚类：模型可以看作是数据的层次结构（树状图）。</li></ul></li><li><p><strong>降维：</strong></p><ul><li>PCA：模型可以看作是一组主成分（新的坐标轴）${v_1, v_2, \dots, v_k}$ 以及将数据从高维空间映射到低维空间的变换矩阵。</li></ul></li><li><p><strong>密度估计：</strong></p><ul><li>高斯混合模型 (GMM)：模型是多个高斯分布的加权和，参数包括每个高斯分布的均值、协方差和权重。</li></ul></li></ul><h4 id="2-策略-Strategy-2"><a href="#2-策略-Strategy-2" class="headerlink" title="2. 策略 (Strategy)"></a>2. 策略 (Strategy)</h4><p>无监督学习的 <strong>策略</strong> 是定义模型好坏的标准。由于没有标签来计算损失，策略通常基于 <strong>数据内在的性质</strong> 来衡量模型对数据结构的拟合程度。它通常是一个 <strong>目标函数</strong>，其优化方向（最大化或最小化）反映了我们希望模型达到的“好”的状态。</p><p><strong>理解：</strong></p><ul><li><strong>内在一致性：</strong> 策略目标是寻找使数据内部结构更清晰、更紧密（对于聚类），或更准确地表示原始数据（对于降维）的模型。</li><li><strong>概率论准则：</strong> 许多无监督学习的策略是基于概率论的，例如最大似然估计，即寻找最能解释观察到数据的概率分布参数。</li><li><strong>几何准则：</strong> 另一些策略是基于几何直观的，例如最小化点到簇中心的距离（K-Means），或最大化数据方差（PCA）。</li></ul><p><strong>常见策略&#x2F;目标函数举例：</strong></p><ul><li><p><strong>聚类：</strong></p><ul><li><strong>K-Means：</strong> 最小化 **簇内平方和 (Within-Cluster Sum of Squares, WCSS)**，也称为 **总误差平方和 (Total Sum of Squared Errors)**。即每个数据点到其所属簇中心的距离的平方和。目标是让同簇的点尽可能近，不同簇的点尽可能远。<br>$J &#x3D; \sum_{j&#x3D;1}^K \sum_{i \in C_j} ||x_i - \mu_j||^2$<br>其中 $C_j$ 是第 $j$ 个簇，$\mu_j$ 是第 $j$ 个簇的中心。</li><li><strong>DBSCAN：</strong> 没有显式的全局目标函数，更多是基于密度的连通性。</li></ul></li><li><p><strong>降维：</strong></p><ul><li><p><strong>PCA：</strong></p><ul><li><strong>最大化方差：</strong> 寻找一组正交的投影方向（主成分），使得数据在这些方向上的方差最大化。这保留了数据最多的信息。</li><li><strong>最小化重构误差：</strong> 寻找一组投影方向，使得原始数据点到其在低维空间中的投影点之间的距离平方和最小。<br>$\min_{W^T W &#x3D; I} ||X - X_k||_F^2$<br>其中 $X_k$ 是 $X$ 在 $k$ 维空间中的重构。这两个目标是等价的。</li></ul></li></ul></li><li><p><strong>密度估计 &#x2F; 概率模型：</strong></p><ul><li><strong>高斯混合模型 (GMM)：</strong> 最大化 **对数似然函数 (Log-Likelihood)**。即在给定模型参数下，观察到所有数据的联合概率（或对数概率）最大。<br>$\max_{\theta} \sum_{i&#x3D;1}^N \log P(x_i | \theta) &#x3D; \max_{\theta} \sum_{i&#x3D;1}^N \log \left( \sum_{k&#x3D;1}^K \alpha_k \mathcal{N}(x_i | \mu_k, \Sigma_k) \right)$<br>其中 $\theta$ 包含所有高斯分布的参数（均值、协方差、权重）。</li></ul></li></ul><h4 id="3-算法-Algorithm-2"><a href="#3-算法-Algorithm-2" class="headerlink" title="3. 算法 (Algorithm)"></a>3. 算法 (Algorithm)</h4><p>无监督学习的 <strong>算法</strong> 是求解策略中定义的优化问题的具体计算方法。它负责找到使目标函数达到最优（最大化或最小化）的模型参数。</p><p><strong>理解：</strong></p><ul><li><strong>迭代优化：</strong> 许多无监督学习问题通常没有简单的解析解，需要通过迭代优化算法来逐步逼近最优解。</li><li><strong>局部最优：</strong> 由于目标函数的非凸性，很多算法可能会收敛到局部最优解，而不是全局最优解。初始化和重复运行有时很重要。</li></ul><p><strong>常见算法举例：</strong></p><ul><li><p><strong>聚类：</strong></p><ul><li><p><strong>K-Means：</strong> 使用 <strong>期望最大化 (EM) 算法的变体</strong>。</p><ol><li><strong>E 步（指派阶段）</strong>：计算每个点到所有簇中心的距离，将每个点分配给最近的簇。</li><li><strong>M 步（更新阶段）</strong>：重新计算每个簇的中心（所有属于该簇的点的平均值）。</li><li>重复 E 步和 M 步，直到簇分配不再改变或簇中心变化很小。</li></ol></li><li><p><strong>层次聚类：</strong> 通常是基于距离矩阵的贪心算法，没有显式的迭代优化。</p></li><li><p><strong>DBSCAN：</strong> 基于密度的遍历算法，发现高密度区域并将其连接。</p></li></ul></li><li><p><strong>降维：</strong></p><ul><li><strong>PCA：</strong> 可以通过 <strong>特征值分解 (Eigenvalue Decomposition)</strong> 或 <strong>奇异值分解 (Singular Value Decomposition, SVD)</strong> 直接计算得到解析解，找到主成分。也可以用迭代算法（如幂迭代法）来近似求解。</li><li><strong>t-SNE：</strong> 基于梯度的优化算法，通过迭代调整数据点在低维空间中的位置，以最小化高维和低维空间中相似度分布之间的 KL 散度。</li></ul></li><li><p><strong>密度估计 &#x2F; 概率模型：</strong></p><ul><li><p><strong>高斯混合模型 (GMM)：</strong> 使用 <strong>期望最大化 (EM) 算法</strong>。</p><ol><li><strong>E 步（期望）</strong>：给定当前模型参数，计算每个数据点属于每个高斯分量的后验概率。</li><li><strong>M 步（最大化）</strong>：利用 E 步计算出的后验概率，重新估计每个高斯分量的参数（均值、协方差、权重），以最大化对数似然。</li><li>重复 E 步和 M 步，直到参数收敛。</li></ol></li></ul></li></ul><hr><h3 id="总结无监督学习的三要素："><a href="#总结无监督学习的三要素：" class="headerlink" title="总结无监督学习的三要素："></a>总结无监督学习的三要素：</h3><table><thead><tr><th align="left">要素</th><th align="left">监督学习中的含义</th><th align="left">无监督学习中的含义</th><th align="left"></th></tr></thead><tbody><tr><td align="left"><strong>模型</strong></td><td align="left">学习一个从输入到输出的映射函数 $f(X)$ 或条件概率 (P(Y</td><td align="left">X))。</td><td align="left"></td></tr><tr><td align="left"><strong>策略</strong></td><td align="left">衡量预测输出与真实标签的差异（如损失函数、经验风险、结构风险）。</td><td align="left">衡量模型对数据内在结构的拟合程度（如簇内距离和、方差、似然函数）。</td><td align="left"></td></tr><tr><td align="left"><strong>算法</strong></td><td align="left">求解最小化损失函数或结构风险的优化问题（如梯度下降）。</td><td align="left">求解最大化似然或最小化结构度量目标函数的优化问题（如 EM 算法、SVD）。</td><td align="left"></td></tr></tbody></table><p>通过这个框架，我们可以系统地理解和分析各种无监督学习方法。每当我们遇到一个新的无监督算法时，都可以尝试去识别它的模型假设是什么，它试图优化什么样的目标函数，以及它是如何通过具体步骤来达到这个优化目标的。</p><h1 id="四-模型评估与模型选择"><a href="#四-模型评估与模型选择" class="headerlink" title="四.模型评估与模型选择"></a>四.模型评估与模型选择</h1><h3 id="模型评估与模型选择"><a href="#模型评估与模型选择" class="headerlink" title="模型评估与模型选择"></a>模型评估与模型选择</h3><p><strong>定义：</strong></p><ul><li>**模型评估 (Model Evaluation)**：指对已训练好的模型进行性能度量，判断其预测能力。这通常通过计算模型在特定数据集（通常是测试集）上的误差指标来完成。</li><li>**模型选择 (Model Selection)**：指在众多候选模型中，根据评估结果选择最适合当前任务和数据的模型。这包括选择模型的类型、复杂度（如多项式次数、神经网络层数）以及超参数（如正则化系数 $\lambda$）。</li></ul><p><strong>重要性：</strong><br>模型评估与选择是统计学习中至关重要的一环。其根本目的是为了选择出 <strong>泛化能力</strong> 强的模型，即在未知数据上也能表现良好的模型。如果只关注模型在训练数据上的表现，很容易陷入 <strong>过拟合</strong>，导致模型在实际应用中失败。</p><hr><h4 id="1-训练误差与测试误差-Training-Error-Test-Error"><a href="#1-训练误差与测试误差-Training-Error-Test-Error" class="headerlink" title="1. 训练误差与测试误差 (Training Error &amp; Test Error)"></a>1. 训练误差与测试误差 (Training Error &amp; Test Error)</h4><ul><li><p>**训练误差 (Training Error)**：模型在 <strong>训练数据集</strong> 上的平均损失。它反映了模型对已知数据的拟合程度。<br>$R_{train}(f) &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N L(y_i, f(x_i))$<br>其中 $L$ 是损失函数，$N$ 是训练样本数。</p></li><li><p>**测试误差 (Test Error)**：模型在 <strong>测试数据集</strong> 上的平均损失。它反映了模型对未知数据的预测能力，是衡量模型泛化能力的重要指标。<br>$R_{test}(f) &#x3D; \frac{1}{N’} \sum_{j&#x3D;1}^{N’} L(y_j, f(x_j))$<br>其中 $N’$ 是测试样本数。测试数据通常是从原始数据集中独立抽样出来，且未参与模型的训练。</p></li></ul><p><strong>理想情况：</strong> 训练误差和测试误差都较小，且两者差距不大。<br><strong>实际问题：</strong> 我们追求的是测试误差最小化，因为这代表了模型的泛化能力。然而，我们只能通过训练数据来学习，而测试数据只用于评估，不能用于模型的学习过程。</p><hr><h4 id="2-过拟合与欠拟合-Overfitting-Underfitting"><a href="#2-过拟合与欠拟合-Overfitting-Underfitting" class="headerlink" title="2. 过拟合与欠拟合 (Overfitting &amp; Underfitting)"></a>2. 过拟合与欠拟合 (Overfitting &amp; Underfitting)</h4><p>这是模型评估与选择中必须理解的核心概念。</p><ul><li><p>**过拟合 (Overfitting)**：</p><ul><li><strong>现象</strong>：模型在训练数据上表现非常好（训练误差很小），但在测试数据上表现很差（测试误差很大）。</li><li><strong>原因</strong>：模型过于复杂，学习到了训练数据中一些特有的、甚至噪声的随机模式，而不是数据的普遍规律。这导致模型对训练数据“记忆”而非“理解”。</li><li><strong>比喻</strong>：学生死记硬背了课本上的所有例题，但遇到稍微变化一点的考题就无法作答。</li><li><strong>示意图</strong>：通常表现为模型曲线通过了训练集的所有点，但在新数据点上波动剧烈，偏离真实趋势。</li></ul></li><li><p>**欠拟合 (Underfitting)**：</p><ul><li><strong>现象</strong>：模型在训练数据和测试数据上都表现很差（训练误差和测试误差都很大）。</li><li><strong>原因</strong>：模型过于简单，无法捕捉数据中的基本模式和趋势。</li><li><strong>比喻</strong>：学生没有掌握基本概念和解题方法，无论是例题还是新题都无法应对。</li><li><strong>示意图</strong>：通常表现为模型曲线过于平滑，无法拟合训练数据的基本趋势。</li></ul></li></ul><p><strong>关系</strong>：<br>过拟合和欠拟合是模型复杂度的两种极端情况。欠拟合时模型复杂度太低，过拟合时模型复杂度太高。模型选择的目标就是在两者之间找到一个最佳平衡点。</p><hr><h4 id="3-模型选择的方法"><a href="#3-模型选择的方法" class="headerlink" title="3. 模型选择的方法"></a>3. 模型选择的方法</h4><p>为了得到泛化能力强的模型，我们不能仅仅依靠训练误差，而需要通过更科学的方法进行模型选择。</p><h5 id="a-正则化-Regularization"><a href="#a-正则化-Regularization" class="headerlink" title="a) 正则化 (Regularization)"></a>a) 正则化 (Regularization)</h5><ul><li><p><strong>目的</strong>：防止过拟合，提高模型泛化能力。</p></li><li><p><strong>原理</strong>：在经验风险（损失函数）的基础上，增加一个惩罚项，限制模型的复杂度。<br>$\min_f \frac{1}{N} \sum_{i&#x3D;1}^N L(y_i, f(x_i)) + \lambda J(f)$</p><ul><li><p><strong>经验风险项</strong>：鼓励模型拟合训练数据。</p></li><li><p>**正则化项 $J(f)$**：鼓励模型简单。它通常是模型参数的范数（如 L1 范数或 L2 范数），表示模型复杂度。</p></li><li><p>**正则化系数 $\lambda$**：一个超参数，用于平衡经验风险和模型复杂度。</p><ul><li>$\lambda$ 越大，对模型复杂的惩罚越大，模型越简单，越可能欠拟合。</li><li>$\lambda$ 越小，对模型复杂的惩罚越小，模型越复杂，越可能过拟合。</li></ul></li></ul></li><li><p><strong>示例</strong>：</p><ul><li>**L1 正则化 (Lasso)**：$J(f) &#x3D; ||w||_1 &#x3D; \sum |w_j|$。倾向于产生稀疏解（一些权重变为 0），可用于特征选择。</li><li>**L2 正则化 (Ridge)**：$J(f) &#x3D; ||w||_2^2 &#x3D; \sum w_j^2$。倾向于使权重变小但非零，有助于处理多重共线性。</li></ul></li></ul><h5 id="b-交叉验证-Cross-Validation"><a href="#b-交叉验证-Cross-Validation" class="headerlink" title="b) 交叉验证 (Cross Validation)"></a>b) 交叉验证 (Cross Validation)</h5><ul><li><p><strong>目的</strong>：更可靠地评估模型的泛化能力，并用于超参数调优和模型选择。避免仅仅依赖一个固定的测试集带来的偶然性。</p></li><li><p><strong>核心思想</strong>：将数据集划分为训练集和验证集（测试集）多次，每次用不同的划分来训练和评估模型，然后取多次评估结果的平均值。</p></li><li><p><strong>常见方法</strong>：</p><ol><li><p>**简单交叉验证 (Holdout Cross Validation)**：</p><ul><li>将数据集随机分成两部分：训练集（例如 70%）和测试集（例如 30%）。</li><li>在训练集上训练模型。</li><li>在测试集上评估模型性能。</li><li><strong>缺点</strong>：评估结果的可靠性高度依赖于数据集的划分。如果划分不当，可能导致评估结果有偏差。</li></ul></li><li><p>**K 折交叉验证 (K-Fold Cross Validation)**：</p><ul><li>将原始数据集随机分成 K 个互不重叠、大小相近的子集（折）。</li><li>进行 K 次迭代：每次取其中一个子集作为 <strong>测试集</strong>，其余 K-1 个子集作为 <strong>训练集</strong>。</li><li>在 K 次迭代中，分别训练模型并记录测试误差。</li><li>最终将 K 次测试误差的平均值作为模型的最终评估结果。</li><li><strong>优点</strong>：每个数据点都被用于训练 K-1 次，并被测试 1 次，因此对数据的利用率高，评估结果更稳定、可靠。</li><li><strong>示例</strong>：5 折交叉验证（K &#x3D; 5），10 折交叉验证（K &#x3D; 10）是常用选择。</li></ul></li><li><p>**留一交叉验证 (Leave-One-Out Cross Validation, LOOCV)**：</p><ul><li>K 折交叉验证的特例，K 等于数据集的样本总数 $N$。</li><li>每次只留一个样本作为测试集，其余 $N-1$ 个样本作为训练集。</li><li>进行 $N$ 次迭代。</li><li><strong>优点</strong>：评估结果几乎无偏。</li><li><strong>缺点</strong>：计算成本非常高，当 $N$ 很大时几乎不可行。</li></ul></li></ol></li><li><p><strong>应用</strong>：交叉验证不仅用于评估模型的最终性能，更常用于 **超参数调优 (Hyperparameter Tuning)**。例如，在选择线性回归的正则化系数 $\lambda$ 时，我们可以尝试不同的 $\lambda$ 值，对每个 $\lambda$ 值都进行 K 折交叉验证，然后选择使平均测试误差最小的 $\lambda$。</p></li></ul><hr><h4 id="4-示例：多项式回归与模型选择"><a href="#4-示例：多项式回归与模型选择" class="headerlink" title="4. 示例：多项式回归与模型选择"></a>4. 示例：多项式回归与模型选择</h4><p><strong>任务：</strong> 使用一个多项式函数拟合一组带有噪声的数据点。</p><p><strong>数据：</strong> 一组 $(x_i, y_i)$ 点，真实关系可能是 $y &#x3D; \sin(\pi x) &#x2F; (\pi x) + \epsilon$，其中 $\epsilon$ 是噪声。</p><p><strong>1. 模型选择（多项式次数）</strong></p><p>我们考虑不同复杂度的模型：</p><ul><li><strong>模型 1</strong>：1 次多项式（线性回归） $f(x) &#x3D; w_1 x + w_0$</li><li><strong>模型 2</strong>：3 次多项式 $f(x) &#x3D; w_3 x^3 + w_2 x^2 + w_1 x + w_0$</li><li><strong>模型 3</strong>：9 次多项式 $f(x) &#x3D; \sum_{j&#x3D;0}^9 w_j x^j$</li></ul><p><strong>训练过程</strong>：<br>我们使用训练数据来拟合这三个多项式模型，目标是最小化平方损失函数。</p><p><strong>观察现象：</strong></p><ul><li><p>**1 次多项式 (欠拟合)**：</p><ul><li><strong>训练误差</strong>：很高。</li><li><strong>测试误差</strong>：也很高。</li><li><strong>原因</strong>：模型过于简单，无法捕捉到数据的非线性趋势。</li><li><strong>图像</strong>：一条直线无法很好地穿过波动的数据点。</li></ul></li><li><p>**3 次多项式 (适度拟合)**：</p><ul><li><strong>训练误差</strong>：较低。</li><li><strong>测试误差</strong>：也较低，且与训练误差接近。</li><li><strong>原因</strong>：模型复杂度适中，成功捕捉了数据的基本非线性趋势。</li><li><strong>图像</strong>：曲线较好地拟合了数据点，同时不过于波动。</li></ul></li><li><p>**9 次多项式 (过拟合)**：</p><ul><li><strong>训练误差</strong>：非常低，甚至接近 0。</li><li><strong>测试误差</strong>：很高。</li><li><strong>原因</strong>：模型过于复杂，不仅拟合了数据的真实模式，还拟合了噪声。模型曲线在训练数据点之间剧烈波动，对训练数据“死记硬背”。</li><li><strong>图像</strong>：曲线穿过了所有训练数据点，但在训练数据点之间和训练数据范围外表现出夸张的波动。</li></ul></li></ul><p><strong>模型评估与选择：</strong><br>根据测试误差（或交叉验证的平均测试误差），我们会选择 <strong>3 次多项式模型</strong>，因为它在未知数据上表现最好。</p><p><strong>2. 正则化在多项式回归中的应用</strong></p><p>假设我们坚持使用 <strong>9 次多项式模型</strong>，但为了防止它过拟合，我们可以引入 <strong>L2 正则化</strong>。</p><ul><li><p><strong>优化目标</strong>：<br>$\min_{w} \sum_{i&#x3D;1}^N (y_i - \sum_{j&#x3D;0}^9 w_j x_i^j)^2 + \lambda \sum_{j&#x3D;0}^9 w_j^2$</p></li><li><p><strong>超参数选择</strong>：正则化系数 $\lambda$ 是一个超参数。我们需要选择一个最佳的 $\lambda$。</p><ul><li><p>我们可以尝试一系列 $\lambda$ 值（例如 0.001, 0.01, 0.1, 1, 10）。</p></li><li><p>对每个 $\lambda$ 值，使用 <strong>K 折交叉验证</strong>。</p><ul><li>将数据分成 K 份。</li><li>重复 K 次：用 K-1 份训练，用剩下的 1 份测试。</li><li>记录 K 次测试误差的平均值。</li></ul></li><li><p><strong>结果</strong>：我们会发现，当 $\lambda$ 较小或为 0 时，9 次多项式仍然过拟合；当 $\lambda$ 过大时，模型又变得过于简单，欠拟合。中间存在一个“最佳”的 $\lambda$ 值，使得模型的平均测试误差最小。这个 $\lambda$ 值可以帮助 9 次多项式模型达到与 3 次多项式模型相似甚至更好的泛化能力，因为它有效地惩罚了那些为了拟合噪声而产生的过大的权重。</p></li></ul></li></ul><hr><p><strong>总结：</strong></p><p>模型评估与模型选择是统计学习实践中不可或缺的环节。</p><ul><li>通过区分 <strong>训练误差</strong> 和 <strong>测试误差</strong>，我们可以诊断模型的拟合状况（过拟合或欠拟合）。</li><li><strong>正则化</strong> 通过在优化目标中引入对模型复杂度的惩罚来直接限制过拟合。</li><li><strong>交叉验证</strong> 通过更稳健的数据划分和多次评估，提供对模型泛化能力的可靠估计，并常用于超参数的优化选择。</li></ul><p>掌握这些概念和技术，是构建健壮、泛化能力强的统计学习模型的关键。</p><h1 id="五-L1-和-L2-正则化"><a href="#五-L1-和-L2-正则化" class="headerlink" title="五. L1 和 L2 正则化"></a>五. L1 和 L2 正则化</h1><h3 id="1-正则化-Regularization-的背景与目的"><a href="#1-正则化-Regularization-的背景与目的" class="headerlink" title="1. 正则化 (Regularization) 的背景与目的"></a>1. 正则化 (Regularization) 的背景与目的</h3><p>在统计学习中，我们的目标是找到一个在训练数据上表现良好，并且在未知数据上也能泛化得很好的模型。然而，过于复杂的模型往往会在训练数据上表现极佳，因为它“记住”了训练数据中的每一个细节，包括噪声。这就是 <strong>过拟合 (Overfitting)</strong> 现象。过拟合的模型在新的、未见过的数据上表现会很差。</p><p><strong>正则化</strong> 就是用来解决过拟合问题的一种技术。它的核心思想是：<strong>在优化目标（通常是经验风险）中添加一个惩罚项，这个惩罚项用来限制模型的复杂度。</strong> 通过这种方式，模型在拟合训练数据的同时，也被“鼓励”保持简单，从而提高其泛化能力。</p><p>正则化项的形式通常是模型参数的范数（norm）。我们主要关注 L1 范数和 L2 范数。</p><hr><h3 id="2-L2-正则化-L2-Regularization-Ridge-Regression"><a href="#2-L2-正则化-L2-Regularization-Ridge-Regression" class="headerlink" title="2. L2 正则化 (L2 Regularization &#x2F; Ridge Regression)"></a>2. L2 正则化 (L2 Regularization &#x2F; Ridge Regression)</h3><ul><li><p><strong>也称为：</strong> 岭回归 (Ridge Regression)。</p></li><li><p><strong>正则化项：</strong> 模型的参数向量 $w$ 的 L2 范数的平方。<br>$J(w) &#x3D; ||w||<em>2^2 &#x3D; \sum</em>{j&#x3D;1}^D w_j^2$<br>（这里通常不包括偏置项 $b$，因为偏置项只影响函数上下平移，不影响函数的复杂度。）</p></li><li><p><strong>优化目标：</strong><br>以线性回归为例，其优化目标是最小化平方损失，加入 L2 正则化后变为：<br>$\min_{w,b} \left( \frac{1}{N} \sum_{i&#x3D;1}^N (y_i - (w^T x_i + b))^2 + \lambda \sum_{j&#x3D;1}^D w_j^2 \right)$<br>其中：</p><ul><li>$\frac{1}{N} \sum_{i&#x3D;1}^N (y_i - (w^T x_i + b))^2$ 是经验风险（平方损失的平均值）。</li><li>$\lambda \sum_{j&#x3D;1}^D w_j^2$ 是 L2 正则化项。</li><li>$\lambda \ge 0$ 是正则化系数（超参数），控制正则化项的权重。</li></ul></li></ul><h4 id="核心作用与特点："><a href="#核心作用与特点：" class="headerlink" title="核心作用与特点："></a>核心作用与特点：</h4><ol><li><p><strong>防止过拟合：</strong> L2 正则化通过惩罚大的权重值，促使模型的权重 $w_j$ 趋向于较小的值。这使得模型对输入数据中的微小变化不那么敏感，从而降低了模型的复杂度。直观上，如果权重都很小，那么任何一个特征对最终预测的影响都不会过大，模型就更“平滑”，不易陷入训练数据的噪声。</p></li><li><p><strong>权重收缩 (Weight Shrinkage)：</strong> L2 正则化会将权重推向零，但 <strong>不会完全变为零</strong>。它使得模型参数值尽可能小，接近于零但不等于零。</p></li><li><p><strong>处理多重共线性：</strong> 当输入特征之间存在高度相关性（多重共线性）时，普通的最小二乘法可能导致权重系数非常大且不稳定。L2 正则化能够通过对权重大小的惩罚来缓解这个问题，提高模型的稳定性和泛化能力。</p></li><li><p><strong>数学直观（几何解释）：</strong> 考虑在二维参数空间 $(w_1, w_2)$ 中，损失函数等高线与正则化约束区域的交点。</p><ul><li>损失函数等高线通常是椭圆。</li><li>L2 正则化项 $\sum w_j^2 \le C$ 对应的是一个以原点为中心的圆形区域（或更高维度的球体）。</li><li>最优解通常发生在损失函数等高线第一次与圆形约束区域相切的点。在这个点上，权重趋向于靠近原点但很少正好在坐标轴上（即权重不会为零）。</li></ul></li></ol><h4 id="导数与优化："><a href="#导数与优化：" class="headerlink" title="导数与优化："></a>导数与优化：</h4><p>L2 正则化项是处处可导的。在梯度下降中，每次更新时，权重会额外减去一个与 $\lambda$ 和当前权重成正比的项：<br>$w_j \leftarrow w_j - \alpha \left( \frac{\partial L}{\partial w_j} + \lambda w_j \right)$<br>这相当于每次更新后，都将 $w_j$ 乘以一个小于 1 的因子 $(1-\alpha \lambda)$，这就是 **权重衰减 (Weight Decay)**。</p><hr><h3 id="L1-正则化-L1-Regularization-Lasso-Regression"><a href="#L1-正则化-L1-Regularization-Lasso-Regression" class="headerlink" title="L1 正则化 (L1 Regularization &#x2F; Lasso Regression)"></a>L1 正则化 (L1 Regularization &#x2F; Lasso Regression)</h3><ul><li><p><strong>也称为：</strong> Lasso 回归 (Least Absolute Shrinkage and Selection Operator)。</p></li><li><p><strong>正则化项：</strong> 模型的参数向量 $w$ 的 L1 范数。<br>$J(w) &#x3D; ||w||<em>1 &#x3D; \sum</em>{j&#x3D;1}^D |w_j|$</p></li><li><p><strong>优化目标：</strong><br>以线性回归为例，其优化目标是最小化平方损失，加入 L1 正则化后变为：<br>$\min_{w,b} \left( \frac{1}{N} \sum_{i&#x3D;1}^N (y_i - (w^T x_i + b))^2 + \lambda \sum_{j&#x3D;1}^D |w_j| \right)$<br>其中：</p><ul><li>$\frac{1}{N} \sum_{i&#x3D;1}^N (y_i - (w^T x_i + b))^2$ 是经验风险。</li><li>$\lambda \sum_{j&#x3D;1}^D |w_j|$ 是 L1 正则化项。</li><li>$\lambda \ge 0$ 是正则化系数。</li></ul></li></ul><h4 id="核心作用与特点：-1"><a href="#核心作用与特点：-1" class="headerlink" title="核心作用与特点："></a>核心作用与特点：</h4><ol><li><p><strong>特征选择 (Feature Selection)：</strong> L1 正则化最大的特点是它能够将一些不重要的特征的权重 <strong>直接压缩为零</strong>。这意味着这些特征被模型彻底“忽略”了。因此，L1 正则化可以用于自动进行特征选择，生成一个更稀疏的模型。当数据集中包含大量冗余或不相关特征时，L1 正则化非常有价值。</p></li><li><p><strong>权重稀疏性 (Sparsity)：</strong> L1 正则化倾向于产生稀疏解，即许多权重为零。这使得模型更简洁，可解释性更强。</p></li><li><p><strong>数学直观（几何解释）：</strong></p><ul><li>L1 正则化项 $\sum |w_j| \le C$ 对应的是一个以原点为中心的正方形区域（或更高维度的菱形&#x2F;八面体）。</li><li>最优解通常发生在损失函数等高线第一次与正方形约束区域相切的点。由于正方形的“角”和“边”在坐标轴上，损失函数等高线更容易在这些角点处相切，导致某些权重恰好为零。</li></ul></li></ol><h4 id="导数与优化：-1"><a href="#导数与优化：-1" class="headerlink" title="导数与优化："></a>导数与优化：</h4><p>L1 正则化项在零点处不可导（绝对值函数的性质），因此不能直接使用梯度下降法。通常需要使用次梯度下降 (Subgradient Descent) 或其他优化算法（如坐标下降法）来求解。</p><hr><h3 id="3-L1-与-L2-正则化的比较总结"><a href="#3-L1-与-L2-正则化的比较总结" class="headerlink" title="3. L1 与 L2 正则化的比较总结"></a>3. L1 与 L2 正则化的比较总结</h3><table><thead><tr><th align="left">特征</th><th align="left">L1 正则化 (Lasso)</th><th align="center">L2 正则化 (Ridge)</th><th></th><th></th></tr></thead><tbody><tr><td align="left"><strong>正则化项</strong></td><td align="left">( \sum</td><td align="center">w_j</td><td></td><td></td></tr><tr><td align="left"><strong>惩罚机制</strong></td><td align="left">惩罚绝对值大小</td><td align="center">惩罚平方和大小</td><td></td><td></td></tr><tr><td align="left"><strong>权重收缩</strong></td><td align="left">使得不重要特征的权重 <strong>变为零</strong></td><td align="center">使得所有权重 <strong>趋近于零但不会变为零</strong></td><td></td><td></td></tr><tr><td align="left"><strong>模型稀疏性</strong></td><td align="left"><strong>会产生稀疏模型</strong>（一些特征被移除），可用于特征选择</td><td align="center"><strong>不会产生稀疏模型</strong>（所有特征保留），所有权重都非零</td><td></td><td></td></tr><tr><td align="left"><strong>模型复杂度</strong></td><td align="left">降低模型复杂度，并进行特征选择</td><td align="center">降低模型复杂度</td><td></td><td></td></tr><tr><td align="left"><strong>几何形状</strong></td><td align="left">正方形&#x2F;菱形（在 2D&#x2F;3D）</td><td align="center">圆形&#x2F;球体（在 2D&#x2F;3D）</td><td></td><td></td></tr><tr><td align="left"><strong>导数特性</strong></td><td align="left">零点不可导</td><td align="center">处处可导</td><td></td><td></td></tr><tr><td align="left"><strong>优化算法</strong></td><td align="left">次梯度下降、坐标下降法等</td><td align="center">梯度下降、解析解（如岭回归的 Normal Equation）</td><td></td><td></td></tr><tr><td align="left"><strong>适用场景</strong></td><td align="left">特征数量很多，需要进行特征选择或模型可解释性强时</td><td align="center">特征之间存在多重共线性时，或所有特征都重要时不希望抛弃任何特征时</td><td></td><td></td></tr></tbody></table><hr><h3 id="4-如何选择-lambda-（正则化系数）？"><a href="#4-如何选择-lambda-（正则化系数）？" class="headerlink" title="4. 如何选择 $\lambda$（正则化系数）？"></a>4. 如何选择 $\lambda$（正则化系数）？</h3><p>$\lambda$ 是一个超参数，它的选择对模型性能至关重要：</p><ul><li><strong>$\lambda &#x3D; 0$：</strong> 没有正则化，模型可能过拟合（等同于普通最小二乘法）。</li><li><strong>$\lambda$ 很小：</strong> 正则化效果不明显，模型仍可能过拟合。</li><li><strong>$\lambda$ 适中：</strong> 在拟合训练数据和保持模型简单之间取得平衡，有助于提高泛化能力。</li><li><strong>$\lambda$ 很大：</strong> 正则化项占据主导，模型过于简单，可能欠拟合（所有权重趋近于零）。</li></ul><p>通常使用 <strong>交叉验证 (Cross Validation)</strong> 来选择最佳的 $\lambda$ 值。例如，使用 K 折交叉验证，尝试一系列不同的 $\lambda$ 值，计算每个 $\lambda$ 值对应的平均测试误差（或验证误差），然后选择使平均测试误差最小的 $\lambda$。</p><h3 id="5-弹性网络-Elastic-Net"><a href="#5-弹性网络-Elastic-Net" class="headerlink" title="5.弹性网络 (Elastic Net)"></a>5.弹性网络 (Elastic Net)</h3><p>L1 和 L2 正则化各有优势，人们也提出了结合两者的 <strong>弹性网络 (Elastic Net)</strong> 正则化。<br>其正则化项是 L1 范数和 L2 范数（或其平方）的线性组合：<br>$\lambda_1 \sum |w_j| + \lambda_2 \sum w_j^2$<br>弹性网络结合了 L1 的特征选择能力和 L2 的处理多重共线性、稳定性的优点。它有两个超参数 $\lambda_1$ 和 $\lambda_2$ 需要调优。</p><h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h3><p>正则化是机器学习中防止过拟合、提高模型泛化能力的核心技术。L1 和 L2 正则化是最常见的两种形式，它们通过对模型参数大小的惩罚来控制模型复杂度。L1 正则化倾向于产生稀疏模型（特征选择），而 L2 正则化则使所有权重变小但不为零（权重衰减）。在实际应用中，根据数据的特点和具体任务的需求，选择合适的正则化方法和正则化系数至关重要。</p><h1 id="六-训练集，验证集和测试集"><a href="#六-训练集，验证集和测试集" class="headerlink" title="六.  训练集，验证集和测试集"></a>六.  训练集，验证集和测试集</h1><h3 id="1-训练集-Training-Set"><a href="#1-训练集-Training-Set" class="headerlink" title="1. 训练集 (Training Set)"></a>1. 训练集 (Training Set)</h3><ul><li><p><strong>定义</strong>：训练集是用于 <strong>训练模型</strong> 的数据集。模型会从训练集中学习特征与标签之间的映射关系、模式、规律，并调整自身的参数（例如，线性回归中的权重和偏置，神经网络中的所有连接权重）。</p></li><li><p><strong>作用</strong>：</p><ul><li><strong>参数学习</strong>：模型通过在训练集上迭代优化（例如，梯度下降），不断减小损失函数，从而更新内部参数。</li><li><strong>模式识别</strong>：模型通过分析训练数据，识别出数据中的内在结构和特征，以便对新的数据进行预测或分类。</li></ul></li><li><p><strong>特点</strong>：</p><ul><li>通常是原始数据集中 <strong>最大的一部分</strong>。</li><li>模型在训练集上表现越好，说明其 <strong>拟合能力越强</strong>。</li><li><strong>不能仅仅根据训练集上的表现来评估模型的最终性能</strong>，因为这容易导致过拟合。</li></ul></li><li><p><strong>使用方式</strong>：</p><ol><li>将原始数据集的绝大部分（如 60%-80%）划分为训练集。</li><li>模型在训练集上进行迭代学习和优化。</li></ol></li></ul><h3 id="2-验证集-Validation-Set"><a href="#2-验证集-Validation-Set" class="headerlink" title="2. 验证集 (Validation Set)"></a>2. 验证集 (Validation Set)</h3><ul><li><p><strong>定义</strong>：验证集是用于 <strong>评估模型性能</strong> 并在模型训练过程中进行 <strong>超参数调优 (Hyperparameter Tuning)</strong> 的数据集。它不参与模型的直接参数学习，但用于指导我们选择最佳的模型结构或超参数。</p></li><li><p><strong>作用</strong>：</p><ul><li><strong>模型选择</strong>：当有多个候选模型（例如，不同层数的神经网络、不同核函数的支持向量机）时，验证集可以帮助我们选择在泛化能力上表现最好的模型。</li><li><strong>超参数调优</strong>：模型的超参数（例如，学习率、正则化系数 $\lambda$、K-Means 中的 K 值、决策树的深度等）是 <strong>在训练之前设定</strong> 的，不能通过训练数据学习。验证集用于评估不同超参数组合下的模型性能，从而选择最佳的超参数组合。</li><li><strong>防止过拟合</strong>：在训练过程中，我们可以定期在验证集上评估模型性能。如果训练误差持续下降而验证误差开始上升，这通常是过拟合的信号，可以据此提前停止训练（早停法）。</li></ul></li><li><p><strong>特点</strong>：</p><ul><li>通常是原始数据集的 <strong>中等大小部分</strong>（如 10%-20%）。</li><li><strong>不用于直接训练模型参数</strong>，但其评估结果会影响我们对模型超参数或结构的决策。</li><li><strong>如果对验证集进行反复调整，模型可能会在验证集上过拟合</strong>（但仍然比直接在测试集上调优要好）。</li></ul></li><li><p><strong>使用方式</strong>：</p><ol><li>从原始数据集中分出一部分作为验证集。</li><li>训练模型时，在训练集上学习参数，在验证集上评估当前模型的性能。</li><li>根据验证集上的性能调整模型的超参数或选择不同的模型架构。</li></ol></li></ul><h3 id="3-测试集-Test-Set"><a href="#3-测试集-Test-Set" class="headerlink" title="3. 测试集 (Test Set)"></a>3. 测试集 (Test Set)</h3><ul><li><p><strong>定义</strong>：测试集是用于 <strong>最终评估模型泛化能力</strong> 的数据集。它在模型的整个开发过程中都 <strong>不参与任何训练和调优</strong>。</p></li><li><p><strong>作用</strong>：</p><ul><li><strong>无偏评估</strong>：提供模型在完全未知数据上的性能的 <strong>无偏估计</strong>。这是模型在真实世界部署后预期表现的最佳预测。</li><li><strong>最终报告</strong>：一旦模型被最终选定并调优完成，只在测试集上运行一次，并将其结果作为模型的最终性能指标向外界报告。</li></ul></li><li><p><strong>特点</strong>：</p><ul><li>通常是原始数据集的 <strong>较小部分</strong>（如 10%-20%）。</li><li><strong>在模型的整个生命周期内，只使用一次测试集进行最终评估。</strong> 任何在测试集上进行的模型选择或超参数调优都会导致测试误差的估计有偏。</li><li>如果测试集性能不佳，说明模型存在问题，可能需要重新回到训练和验证阶段，调整超参数甚至模型架构。</li></ul></li><li><p><strong>使用方式</strong>：</p><ol><li>将原始数据集的 <strong>一小部分完全独立地留作测试集</strong>，并确保在模型开发过程中不接触它。</li><li>只有在模型训练和验证（包括超参数调优）全部完成后，才使用测试集进行一次最终评估。</li></ol></li></ul><h3 id="4-为什么要区分这三个数据集？"><a href="#4-为什么要区分这三个数据集？" class="headerlink" title="4. 为什么要区分这三个数据集？"></a>4. 为什么要区分这三个数据集？</h3><p>将数据集划分为训练集、验证集和测试集是机器学习中一项基本而关键的最佳实践，其核心目的是 <strong>确保模型拥有良好的泛化能力</strong>，并对模型的性能进行 <strong>无偏、可靠的评估</strong>。</p><ol><li><p><strong>避免过拟合</strong>：</p><ul><li>如果只用训练集评估模型，很容易选到在训练集上表现好但泛化能力差的过拟合模型。</li><li>验证集帮助我们在训练过程中检测过拟合，并在超参数调整时避免在训练数据上过拟合。</li><li>测试集则提供最终的“金标准”，防止模型对训练集和验证集都过拟合。</li></ul></li><li><p><strong>超参数优化</strong>：</p><ul><li>超参数无法通过训练集学习，需要通过在验证集上的表现来选择。</li><li>如果在训练集上选择超参数，会引入偏差，并可能导致训练集上的过拟合。</li><li>如果在测试集上选择超参数，会导致测试集上的过拟合，从而高估模型的泛化能力。</li></ul></li><li><p><strong>无偏性能评估</strong>：</p><ul><li>测试集的存在，确保我们对模型在完全陌生数据上的表现有一个诚实、无偏的估计。</li><li>只有通过从未见过的数据进行评估，才能真正衡量模型部署到真实世界后的效果。</li></ul></li></ol><h3 id="5-数据集划分的常用比例"><a href="#5-数据集划分的常用比例" class="headerlink" title="5. 数据集划分的常用比例"></a>5. 数据集划分的常用比例</h3><p>常见的划分比例有：</p><ul><li><p><strong>简单划分</strong>：</p><ul><li>训练集：测试集 &#x3D; 70% : 30% 或 80% : 20%</li><li>这种情况下，验证集可能被省略，或者直接将一部分训练集作为验证集（但这样训练集会进一步缩小）。</li></ul></li><li><p><strong>经典三段式划分</strong>：</p><ul><li>训练集：验证集：测试集 &#x3D; 60% : 20% : 20% 或 70% : 15% : 15%</li><li>这是最推荐的做法，在有足够数据的情况下。</li></ul></li><li><p>**K 折交叉验证 (K-Fold Cross-Validation)**：</p><ul><li><p>当数据量相对较小，或者希望更充分利用数据时，可以使用 K 折交叉验证来代替固定的验证集。</p></li><li><p><strong>步骤</strong>：</p><ol><li>将整个数据集分成 K 份。</li><li>进行 K 次迭代：每次取其中一份作为 <strong>验证集</strong>，其余 K-1 份作为 <strong>训练集</strong>。</li><li>在 K 次迭代中，分别训练模型并记录在验证集上的性能。</li><li>将 K 次验证性能的平均值作为当前超参数组合的评估结果。</li><li>选择最佳超参数组合后，使用最佳超参数在**整个训练集（原始数据集减去测试集）**上重新训练最终模型。</li><li>最后，在独立的 <strong>测试集</strong> 上评估最终模型的性能。</li></ol></li><li><p><strong>优点</strong>：数据利用率高，评估结果更稳定可靠。</p></li><li><p><strong>缺点</strong>：计算成本更高。</p></li></ul></li></ul><h3 id="6-示例：猫狗分类器开发"><a href="#6-示例：猫狗分类器开发" class="headerlink" title="6. 示例：猫狗分类器开发"></a>6. 示例：猫狗分类器开发</h3><p>假设我们正在开发一个图像分类器，目标是识别图片中是猫还是狗。我们有 10000 张标注好的图片。</p><ol><li><p><strong>数据划分</strong>：</p><ul><li><strong>训练集</strong> (例如：7000 张图片)：用于训练神经网络，让它学习猫和狗的视觉特征。</li><li><strong>验证集</strong> (例如：1500 张图片)：用于调整神经网络的超参数（如学习率、网络层数、是否使用 Dropout、正则化强度）。例如，我们尝试不同的学习率（0.1, 0.01, 0.001），在训练集上训练，然后在验证集上评估准确率，选择在验证集上准确率最高的学习率。</li><li><strong>测试集</strong> (例如：1500 张图片)：在所有超参数都确定，模型结构也选好之后，我们只用测试集进行一次最终评估，得到模型在未知数据上的最终准确率。</li></ul></li><li><p><strong>开发流程</strong>：</p><ul><li><strong>循环迭代</strong>：在训练集上训练多个 epoch，并定期在验证集上评估性能。</li><li><strong>超参数调优</strong>：如果验证集性能不理想，调整学习率、批次大小、正则化系数等超参数，然后重新在训练集上训练并再次在验证集上评估。这个过程可能会重复多次。</li><li><strong>模型选择</strong>：如果尝试了不同的神经网络架构（例如，一个 5 层，一个 10 层），则在验证集上比较它们的性能，选择表现更好的架构。</li><li><strong>最终评估</strong>：一旦对模型的表现和超参数选择感到满意，并且不再进行任何调整时，才在 <strong>测试集</strong> 上进行一次最终的评估，并报告这个结果。</li></ul></li></ol><p>通过这种严格的划分和使用流程，我们能够确保我们最终发布的模型在面对真实世界的新数据时，能够真正地表现出我们所报告的性能水平。</p><h3 id="7-K-折交叉验证进行超参数调优的-流程"><a href="#7-K-折交叉验证进行超参数调优的-流程" class="headerlink" title="7.  K 折交叉验证进行超参数调优的      流程"></a>7.  K 折交叉验证进行超参数调优的      流程</h3><ol><li><p><strong>初始数据划分：</strong></p><ul><li><p>首先，将你的原始数据集划分为两大部分：</p><ul><li>**训练&#x2F;验证集 (Training&#x2F;Validation Data)**：用于模型的训练和超参数的调优（比如 80% 的数据）。</li><li>**最终测试集 (Test Set)**：完全独立保留，只用于最终模型的无偏性能评估（比如 20% 的数据）。</li></ul></li></ul></li><li><p><strong>超参数调优阶段 (在“训练&#x2F;验证集”上执行 K 折交叉验证)：</strong></p><ul><li><p>目标：找出最佳的超参数组合（例如，L2 正则化系数 $\lambda$）。</p></li><li><p><strong>步骤 A: 定义候选超参数</strong></p><ul><li>列出你想要尝试的超参数值列表，例如 <code>lambda_values = [0.001, 0.01, 0.1, 1, 10]</code>。</li></ul></li><li><p><strong>步骤 B: 对每个超参数组合执行 K 折交叉验证</strong></p><ul><li><p>对于 <code>lambda_values</code> 中的每一个 $\lambda$:</p><ul><li><p>在 <strong>训练&#x2F;验证集</strong> 这部分数据上执行 K 折交叉验证（例如，K &#x3D; 5）。</p></li><li><p><strong>K 次迭代循环：</strong></p><ul><li><p>将“训练&#x2F;验证集”分成 K 个子集。</p></li><li><p>在每次迭代中：</p><ul><li>**一个子集被指定为当前迭代的“验证折”(Validation Fold)**。</li><li>**其余 K-1 个子集合并作为当前迭代的“训练折”(Training Fold)**。</li><li>使用当前选定的 $\lambda$ 值，在**“训练折”<strong>上训练模型，优化其</strong> 模型参数**（例如 $w, b$）。</li><li>使用训练好的模型，在**“验证折”**上评估其性能（计算验证误差、准确率等）。</li></ul></li></ul></li><li><p><strong>计算交叉验证分数：</strong> 将这 K 次在“验证折”上得到的性能指标取 <strong>平均值</strong>。这个平均值就是当前 $\lambda$ 值的**“交叉验证分数”**。</p></li></ul></li></ul></li><li><p><strong>步骤 C: 选择最佳超参数</strong></p><ul><li>比较所有候选 $\lambda$ 值对应的“交叉验证分数”。</li><li>选择使“交叉验证分数”最佳（例如，验证误差最小或准确率最高）的那个 $\lambda$。这个 $\lambda$ 就是我们确定的 <strong>最佳超参数</strong>。</li></ul></li></ul></li><li><p><strong>最终模型训练阶段：</strong></p><ul><li>使用在步骤 C 中确定的 <strong>最佳超参数</strong>。</li><li>在 <strong>整个“训练&#x2F;验证集”</strong>（即步骤 1 中最初划分为训练&#x2F;验证的那一部分数据）上 <strong>重新训练模型</strong>。此时，模型会利用所有可用的训练数据来学习其最终的 <strong>模型参数</strong>。</li></ul></li><li><p><strong>最终模型评估阶段：</strong></p><ul><li>使用在步骤 3 中训练好的 <strong>最终模型</strong>。</li><li>在 <strong>最终测试集</strong>（即步骤 1 中完全独立保留的那一部分数据）上进行 <strong>一次性评估</strong>。</li><li>这个结果就是模型在真实世界中预期性能的 <strong>无偏估计</strong>。</li></ul></li></ol><p>K 折交叉验证在超参数调优阶段，确实是通过计算多次“验证折”性能的平均值来作为超参数组合的“得分”，从而指导我们选择最佳的超参数。</p><h1 id="七-泛化能力"><a href="#七-泛化能力" class="headerlink" title="七. 泛化能力"></a>七. 泛化能力</h1><h3 id="泛化能力-Generalization-Ability"><a href="#泛化能力-Generalization-Ability" class="headerlink" title="泛化能力 (Generalization Ability)"></a>泛化能力 (Generalization Ability)</h3><p><strong>定义：</strong><br>泛化能力是指 <strong>学习方法（模型）对未知数据（或未见过的数据）进行预测的能力</strong>。一个具有良好泛化能力的模型，不仅在训练数据上表现良好，而且在遇到新的、未见过的数据时，也能保持较高的准确性。</p><p><strong>核心问题：</strong><br>统计学习的根本目标不是在训练数据上表现完美，而是要构建一个具有强泛化能力，能够应用于真实世界新数据的模型。在训练数据上表现再好，如果不能泛化到新数据，这个模型就没有实际价值。</p><h3 id="1-泛化误差-Generalization-Error"><a href="#1-泛化误差-Generalization-Error" class="headerlink" title="1. 泛化误差 (Generalization Error)"></a>1. 泛化误差 (Generalization Error)</h3><ul><li><strong>定义：</strong> 泛化误差是指模型在 <strong>所有可能数据</strong> 上（即对数据真实分布 $P(X, Y)$ 的期望）的期望损失。<br>$R_{exp}(f) &#x3D; E_P[L(Y, f(X))] &#x3D; \int_{X \times Y} L(y, f(x)) P(x, y) dx dy$<br>其中，$L(Y, f(X))$ 是损失函数，$P(X, Y)$ 是数据的真实联合概率分布。</li><li><strong>理想目标：</strong> 统计学习的最终目标是找到一个使泛化误差最小的模型 $f^*$。<br>$f^* &#x3D; \arg \min_f R_{exp}(f)$</li><li><strong>实际困境：</strong> 由于数据的真实分布 $P(X, Y)$ 是未知的，我们无法直接计算泛化误差，也无法直接最小化它。</li></ul><h3 id="2-泛化误差的估计与替代"><a href="#2-泛化误差的估计与替代" class="headerlink" title="2. 泛化误差的估计与替代"></a>2. 泛化误差的估计与替代</h3><p>由于无法直接计算泛化误差，我们通常通过以下方式对其进行估计和替代：</p><ul><li><p>**测试误差 (Test Error)**：</p><ul><li><strong>定义：</strong> 模型在独立同分布（i.i.d.）抽样出来的 <strong>测试集</strong> 上的平均损失。</li><li><strong>作用：</strong> 测试误差是泛化误差的 <strong>无偏估计</strong>。当测试集足够大，且与训练集独立同分布时，测试误差能够很好地近似泛化误差。</li><li><strong>计算公式：</strong><br>$R_{test}(f) &#x3D; \frac{1}{N’} \sum_{j&#x3D;1}^{N’} L(y_j, f(x_j))$<br>其中 $N’$ 是测试样本数。</li></ul></li><li><p>**交叉验证 (Cross Validation)**：</p><ul><li><strong>作用：</strong> 尤其在数据量有限时，K 折交叉验证能提供比单一测试集更稳定、更可靠的泛化误差估计。它通过多次划分和评估，减少了评估结果对特定数据划分的偶然性依赖。</li><li><strong>过程：</strong> 对数据集进行 K 次划分，每次用 K-1 份训练，1 份验证，然后取 K 次验证误差的平均值。</li></ul></li></ul><h3 id="3-泛化能力的衡量与挑战"><a href="#3-泛化能力的衡量与挑战" class="headerlink" title="3. 泛化能力的衡量与挑战"></a>3. 泛化能力的衡量与挑战</h3><p>模型的泛化能力通常通过 <strong>测试误差</strong> 来衡量。挑战在于：</p><ul><li>**过拟合 (Overfitting)**：模型在训练数据上表现很好，但泛化能力差。这是因为模型学习到了训练数据中的噪声和特有模式，而不是普遍规律。表现为训练误差远小于测试误差。</li><li>**欠拟合 (Underfitting)**：模型在训练数据和测试数据上表现都差。这是因为模型过于简单，无法学习到数据的基本模式。表现为训练误差和测试误差都很大。</li></ul><p><strong>良好的泛化能力</strong> 意味着模型在训练误差和测试误差之间取得了良好的平衡。我们希望选择的模型既能很好地拟合训练数据（训练误差小），又能很好地泛化到新数据（测试误差小）。</p><h3 id="4-泛化误差上界-Generalization-Error-Bound"><a href="#4-泛化误差上界-Generalization-Error-Bound" class="headerlink" title="4. 泛化误差上界 (Generalization Error Bound)"></a>4. 泛化误差上界 (Generalization Error Bound)</h3><ul><li><p><strong>概念：</strong> 泛化误差上界是统计学习理论中的一个重要概念。它提供了一个理论值，用于衡量模型的泛化误差 <strong>不会超过</strong> 某个上界。</p><ul><li>通常表示为：$R_{exp}(f) \le R_{emp}(f) + \text{某个复杂度项}$</li><li>或者：$R_{exp}(f) \le R_{test}(f) + \text{某个置信区间}$</li></ul></li><li><p><strong>作用：</strong></p><ul><li><strong>理论分析：</strong> 泛化误差上界从理论上解释了为什么结构风险最小化（SRM）策略能够有效防止过拟合。结构风险函数包含了经验风险项和代表模型复杂度的正则化项。通过限制模型复杂度，就是在控制泛化误差上界中的复杂度项。</li><li><strong>指导模型设计：</strong> 帮助理解模型复杂度、样本数量和泛化能力之间的关系。</li><li><strong>不作为实际评估：</strong> 尽管有理论意义，泛化误差上界通常是比较宽松的，不直接用于模型选择或性能报告，因为实际测试误差的估计更为精确和实用。</li></ul></li></ul><h3 id="5-影响泛化能力的因素"><a href="#5-影响泛化能力的因素" class="headerlink" title="5. 影响泛化能力的因素"></a>5. 影响泛化能力的因素</h3><p>有几个关键因素会影响模型的泛化能力：</p><ol><li><p>**模型复杂度 (Model Complexity)**：</p><ul><li>模型越复杂，其表示能力越强，越容易拟合训练数据，但也越容易过拟合。</li><li>模型越简单，越不容易过拟合，但可能欠拟合。</li><li>需要在两者之间找到一个最佳平衡点。</li></ul></li><li><p>**训练数据量 (Amount of Training Data)**：</p><ul><li>训练数据量越大，模型学到的模式越接近真实数据分布，泛化能力越强。</li><li>数据量小，模型容易捕捉到噪声，导致过拟合。</li></ul></li><li><p>**特征数量和质量 (Number and Quality of Features)**：</p><ul><li><strong>特征过多</strong>（尤其是不相关特征），可能增加模型复杂度，导致过拟合。</li><li><strong>特征过少</strong>，可能导致模型无法学习到足够的信息，导致欠拟合。</li><li>高质量、有代表性的特征对泛化能力至关重要。</li></ul></li><li><p>**正则化 (Regularization)**：</p><ul><li>通过对模型参数施加惩罚，限制模型复杂度，是提高泛化能力最常用的技术之一。L1、L2 正则化都是为了这个目的。</li></ul></li><li><p>**损失函数与优化算法 (Loss Function and Optimization Algorithm)**：</p><ul><li>选择合适的损失函数能够更好地指导模型学习。</li><li>高效且能够找到全局或良好局部最优的优化算法也有助于训练出泛化能力强的模型。</li></ul></li><li><p>**数据分布的代表性 (Representativeness of Data Distribution)**：</p><ul><li>训练数据、验证数据和测试数据都应该从相同的、能够代表真实世界场景的分布中独立同分布地抽取。</li><li>如果数据分布不一致（例如，训练数据与实际应用数据有显著差异），模型即使在训练集和测试集上表现良好，在实际应用中也可能泛化失败。</li></ul></li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>泛化能力是统计学习模型最重要的衡量标准。我们通过 <strong>测试误差</strong>（或 K 折交叉验证平均误差）来估计泛化能力，并通过各种策略（如控制模型复杂度、正则化、增加数据量、特征工程）来提高模型的泛化能力，以期在未知数据上也能取得良好的表现。理解并关注泛化能力是构建成功机器学习应用的关键。</p><h1 id="八-区分风险函数"><a href="#八-区分风险函数" class="headerlink" title="八.区分风险函数"></a>八.<strong>区分风险函数</strong></h1><h3 id="风险函数、期望损失、经验风险、经验损失、训练误差、测试误差、泛化误差的区别与联系"><a href="#风险函数、期望损失、经验风险、经验损失、训练误差、测试误差、泛化误差的区别与联系" class="headerlink" title="风险函数、期望损失、经验风险、经验损失、训练误差、测试误差、泛化误差的区别与联系"></a>风险函数、期望损失、经验风险、经验损失、训练误差、测试误差、泛化误差的区别与联系</h3><p>这些概念都是统计学习中用于 <strong>衡量模型好坏</strong> 的核心指标，它们在 <strong>定义、计算方式、数据来源、理论意义</strong> 等方面有细微但重要的区别。许多表达式看起来相似（如都涉及损失函数 $L$ 的平均），但本质上反映了模型在 <strong>不同数据集合</strong> 或 <strong>不同分布</strong> 上的表现。下面我将 <strong>逐一详细定义</strong>，并通过 <strong>表格对比</strong>、<strong>公式解析</strong>、<strong>关系图解</strong> 和 <strong>例子</strong> 来全面讲解。</p><hr><h4 id="1-核心公式回顾（损失函数基础）"><a href="#1-核心公式回顾（损失函数基础）" class="headerlink" title="1. 核心公式回顾（损失函数基础）"></a>1. 核心公式回顾（损失函数基础）</h4><p>所有这些指标都基于 <strong>损失函数</strong> $L(Y, f(X))$：</p><ul><li>它度量模型预测 $f(X)$ 与真实值 $Y$ 的不一致程度。</li><li>常见例子：平方损失 $L &#x3D; (Y - f(X))^2$、0-1 损失 $L &#x3D; \mathbb{I}(Y \neq f(X))$。</li></ul><hr><h4 id="2-逐一定义与区别"><a href="#2-逐一定义与区别" class="headerlink" title="2. 逐一定义与区别"></a>2. 逐一定义与区别</h4><table><thead><tr><th>概念</th><th>别名</th><th align="center">定义与公式</th><th>数据来源 &#x2F; 分布</th><th>理论意义与用途</th></tr></thead><tbody><tr><td><strong>风险函数</strong><br>(Risk Function)</td><td><strong>期望损失</strong><br>(Expected Loss)</td><td align="center">模型关于 <strong>真实联合分布</strong> $P(X,Y)$ 的 <strong>期望损失</strong>。<br>$R_{\exp}(f) &#x3D; E_P[L(Y, f(X))] &#x3D; \int_{X \times Y} L(y, f(x)) P(x,y) , dx , dy$</td><td><strong>未知的真实数据分布</strong> $P(X,Y)$</td><td><strong>理论最优目标</strong>：统计学习追求最小化风险函数的模型 $f^*$。<br>无法直接计算，只能理论分析。</td></tr><tr><td><strong>经验风险</strong><br>(Empirical Risk)</td><td><strong>经验损失</strong><br>(Empirical Loss)</td><td align="center">模型在 <strong>训练数据集</strong> 上的 <strong>平均损失</strong>。<br>$R_{\emp}(f) &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N L(y_i, f(x_i))$</td><td><strong>训练集</strong>（$N$ 个样本）</td><td><strong>实际优化目标</strong>：经验风险最小化（ERM）策略直接在训练集上最小化它。<br>易导致过拟合。</td></tr><tr><td><strong>训练误差</strong><br>(Training Error)</td><td>-</td><td align="center">与经验风险 <strong>完全等价</strong>（书中有时互用）。<br>公式同经验风险。</td><td><strong>训练集</strong></td><td><strong>诊断拟合程度</strong>：训练误差小说明模型拟合训练数据好，但不代表泛化好。</td></tr><tr><td><strong>测试误差</strong><br>(Test Error)</td><td>-</td><td align="center">模型在 <strong>独立测试数据集</strong> 上的 <strong>平均损失</strong>。<br>$R_{\test}(f) &#x3D; \frac{1}{N’} \sum_{j&#x3D;1}^{N’} L(y_j, f(x_j))$</td><td><strong>测试集</strong>（$N’$ 个样本，独立于训练集）</td><td><strong>泛化能力的实用估计</strong>：无偏估计泛化误差。用于最终模型评估。</td></tr><tr><td><strong>泛化误差</strong><br>(Generalization Error)</td><td>-</td><td align="center"><strong>等同于风险函数&#x2F;期望损失</strong>（书中有时互用）。<br>公式同 $R_{\exp}(f)$。</td><td><strong>未知的真实分布</strong> $P(X,Y)$</td><td><strong>最终追求目标</strong>：反映模型在所有未知数据上的平均表现。无法直接计算，用测试误差估计。</td></tr></tbody></table><p><strong>关键澄清（为什么表达式相似却不同）</strong>：</p><ul><li><p><strong>相同点</strong>：都基于损失函数 $L$ 的 <strong>平均</strong>（积分或求和）。</p></li><li><p><strong>不同点</strong>：</p><ul><li><strong>积分 vs 求和</strong>：风险&#x2F;泛化误差是 <strong>连续积分</strong>（期望），其他是 <strong>离散求和</strong>（样本平均）。</li><li><strong>分布 vs 样本</strong>：风险&#x2F;泛化误差依赖 <strong>未知真实分布</strong> $P$；经验风险&#x2F;训练误差依赖 <strong>训练样本</strong>；测试误差依赖 <strong>测试样本</strong>。</li><li><strong>可计算性</strong>：经验风险、训练误差、测试误差 <strong>可直接计算</strong>；风险函数、泛化误差 <strong>不可直接计算</strong>。</li></ul></li></ul><hr><h4 id="3-关系图解（从理论到实践）"><a href="#3-关系图解（从理论到实践）" class="headerlink" title="3. 关系图解（从理论到实践）"></a>3. 关系图解（从理论到实践）</h4><figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">真实世界分布 P<span class="comment">(X,Y)</span>  ←未知→</span><br><span class="line">     ↓ <span class="comment">(积分期望)</span></span><br><span class="line">风险函数 / 期望损失 / 泛化误差  ←理论目标，无法计算→</span><br><span class="line">     ↓ <span class="comment">(i.i.d. 抽样)</span></span><br><span class="line">训练集 <span class="comment">(N 个样本)</span>          测试集 <span class="comment">(N&#x27; 个样本，独立)</span></span><br><span class="line">     ↓ <span class="comment">(平均求和)</span>                ↓ <span class="comment">(平均求和)</span></span><br><span class="line">经验风险 / 经验损失 / 训练误差    测试误差</span><br><span class="line">     ↓ <span class="comment">(最小化)</span>                  ↓ <span class="comment">(估计)</span></span><br><span class="line">模型参数优化 <span class="comment">(ERM/SRM)</span>    ←→ 泛化能力评估 <span class="comment">(无偏估计泛化误差)</span></span><br></pre></td></tr></table></figure><ul><li><strong>箭头 1</strong>：经验风险是对风险函数的 <strong>近似</strong>（大数定律：当 $N \to \infty$ 时，$R_{\emp} \approx R_{\exp}$」）。</li><li><strong>箭头 2</strong>：测试误差是对泛化误差的 <strong>无偏估计</strong>（当测试集大且 i.i.d. 时，$R_{\test} \approx R_{\exp}$」）。</li><li><strong>过拟合诊断</strong>：$R_{\emp} \ll R_{\test}$ → 过拟合；$R_{\emp} \approx R_{\test}$ 且都小 → 泛化好。</li></ul><hr><h4 id="4-例子说明（线性回归，平方损失）"><a href="#4-例子说明（线性回归，平方损失）" class="headerlink" title="4. 例子说明（线性回归，平方损失）"></a>4. 例子说明（线性回归，平方损失）</h4><p>假设真实模型：$y &#x3D; 2x + 1 + \epsilon$（$\epsilon$ 是噪声）。</p><ul><li><strong>训练集</strong>：10 个点，经验风险&#x2F;训练误差 &#x3D; 0.15（拟合好）。</li><li><strong>测试集</strong>：100 个新点，测试误差 &#x3D; 0.18（接近真实）。</li><li><strong>风险函数&#x2F;泛化误差</strong>：理论值 ≈ 0.17（噪声方差），无法直接算，但测试误差估计它。</li><li><strong>如果过拟合</strong>：用 9 次多项式，训练误差 ≈ 0.01（记住噪声），但测试误差 &#x3D; 5.2（泛化差）。</li></ul><hr><h4 id="5-实际应用与注意事项"><a href="#5-实际应用与注意事项" class="headerlink" title="5. 实际应用与注意事项"></a>5. 实际应用与注意事项</h4><ol><li><p><strong>优化时</strong>：用 <strong>经验风险&#x2F;训练误差</strong> 最小化（梯度下降等）。</p></li><li><p><strong>防止过拟合</strong>：加正则化 → 结构风险 $R_{srm} &#x3D; R_{\emp} + \lambda J(f)$。</p></li><li><p><strong>模型选择</strong>：用 <strong>测试误差</strong> 或 <strong>交叉验证平均误差</strong> 估计泛化。</p></li><li><p><strong>最终报告</strong>：只用 <strong>独立测试集</strong> 的测试误差作为泛化误差估计。</p></li><li><p><strong>书中的互用</strong>：</p><ul><li>“风险函数 &#x3D; 期望损失 &#x3D; 泛化误差”：强调理论层面。</li><li>“经验风险 &#x3D; 经验损失 &#x3D; 训练误差”：强调训练集层面。</li></ul></li></ol><p><strong>总结</strong>：这些概念层层递进，从 <strong>理论最优（风险&#x2F;泛化误差）</strong> → <strong>训练近似（经验风险&#x2F;训练误差）</strong> → <strong>泛化估计（测试误差）</strong>。掌握区别，就能科学地训练、评估和选择模型！</p><h1 id="九-泛化误差上界"><a href="#九-泛化误差上界" class="headerlink" title="九.泛化误差上界"></a>九.泛化误差上界</h1><p><strong>核心思想：</strong><br>泛化误差上界旨在从 <strong>理论上</strong> 给出一个 <strong>概率估计</strong>，说明一个学习算法的泛化误差不会超过某个特定的值。它通常是一个不等式，将泛化误差与经验误差、模型复杂度以及样本数量联系起来。</p><p><strong>直观理解：</strong><br>我们知道泛化误差是模型在所有未知数据上的期望损失，是无法直接计算的。但我们可以计算在有限训练集上的经验误差。泛化误差上界告诉我们：<strong>“在大多数情况下，模型的真实泛化误差不会比它的经验误差加上一个与模型复杂度、样本数量和置信度相关的项大太多。”</strong></p><h3 id="1-泛化误差上界的理论基础"><a href="#1-泛化误差上界的理论基础" class="headerlink" title="1. 泛化误差上界的理论基础"></a>1. 泛化误差上界的理论基础</h3><p>泛化误差上界主要依赖于 <strong>统计学习理论</strong> 中的几个重要定理和概念：</p><ul><li>**大数定律 (Law of Large Numbers)**：当样本数量足够大时，样本的平均值会接近于总体的期望值。这解释了为什么经验风险可以作为泛化风险的近似。</li><li>**一致收敛性 (Uniform Convergence)**：对于一个给定的函数集合（模型空间），当样本数量足够大时，经验风险函数会一致收敛到泛化风险函数。</li><li><strong>VC 维 (Vapnik-Chervonenkis Dimension)</strong> 或 **Rademacher 复杂度 (Rademacher Complexity)**：用于衡量模型空间的 <strong>复杂度</strong>。复杂度越高，模型能够拟合的函数种类越多，但也越容易过拟合。</li></ul><h3 id="2-泛化误差上界的一般形式"><a href="#2-泛化误差上界的一般形式" class="headerlink" title="2. 泛化误差上界的一般形式"></a>2. 泛化误差上界的一般形式</h3><p>泛化误差上界通常具有以下形式：</p><p>$R_{exp}(f) \le R_{emp}(f) + \text{复杂度项} + \text{置信度项}$</p><p>更具体地，一个常见的表示形式是（适用于二分类问题）：</p><p>对于任意函数 $f \in \mathcal{H}$ (假设空间中的任意一个函数)，在至少 $1-\delta$ 的概率下（其中 $\delta$ 是一个很小的正数，表示不满足不等式的概率），有：</p><p>$R_{exp}(f) \le R_{emp}(f) + \Omega(N, d, \delta)$</p><p>其中：</p><ul><li><p>$R_{exp}(f)$：模型的 <strong>泛化误差</strong>（期望风险）。</p></li><li><p>$R_{emp}(f)$：模型的 <strong>经验误差</strong>（经验风险），在训练集上计算。</p></li><li><p>$\Omega(N, d, \delta)$：一个 **复杂度项 (Complexity Term)**，它是一个非负值，与以下因素有关：</p><ul><li>$N$：训练样本数量。通常，$N$ 越大，$\Omega$ 越小。</li><li>$d$：假设空间 $\mathcal{H}$ 的复杂度度量（例如 VC 维或 Rademacher 复杂度）。通常，$d$ 越大，$\Omega$ 越大。</li><li>$\delta$：置信度参数。通常，$\delta$ 越小（即置信度越高），$\Omega$ 越大。</li></ul></li></ul><p>这个不等式表明：<strong>泛化误差不会比经验误差加上一个由样本数、模型复杂度、置信度决定的“惩罚项”更大。</strong></p><h3 id="3-VC-维理论下的泛化误差上界（以二分类为例）"><a href="#3-VC-维理论下的泛化误差上界（以二分类为例）" class="headerlink" title="3. VC 维理论下的泛化误差上界（以二分类为例）"></a>3. VC 维理论下的泛化误差上界（以二分类为例）</h3><p>在统计学习理论中，Vapnik-Chervonenkis (VC) 维是衡量一个二分类假设空间 $\mathcal{H}$ 复杂度的一个重要概念。</p><p>**VC 维 (VC Dimension)**：一个假设空间 $\mathcal{H}$ 的 VC 维 $d_{VC}(\mathcal{H})$ 是它能 <strong>打散 (shatter)</strong> 的最大样本数量。如果一个假设空间能打散任意 $d$ 个样本，但不能打散任意 $d+1$ 个样本，则其 VC 维为 $d$。</p><ul><li><strong>打散</strong>：指对于任意 $d$ 个样本，假设空间 $\mathcal{H}$ 都能实现这 $d$ 个样本的所有 $2^d$ 种可能的二分类。</li></ul><p><strong>Hoeffding 不等式 (Hoeffding’s Inequality)</strong> 和 <strong>VC 维理论</strong> 结合起来，可以导出如下泛化误差上界（对于 0-1 损失）：</p><p>对于任意函数 $f \in \mathcal{H}$，在训练样本数量为 $N$ 时，至少以 $1-\delta$ 的概率，有：</p><p>$R_{exp}(f) \le R_{emp}(f) + \sqrt{\frac{d_{VC}(\mathcal{H}) \left( \log \frac{2N}{d_{VC}(\mathcal{H})} + 1 \right) + \log \frac{4}{\delta}}{N}}$</p><p><strong>分析这个公式：</strong></p><ul><li><p>**经验误差 $R_{emp}(f)$**：模型在训练集上的错误率。</p></li><li><p><strong>后面的根号项</strong> 就是复杂度项 $\Omega$，它受到以下因素影响：</p><ul><li>**$d_{VC}(\mathcal{H})$ (VC 维)**：衡量模型复杂度。VC 维越大，模型越复杂，上界越大（越宽松）。</li><li><ul><li>*$N$ (样本数量)**：样本数量 $N$ 越大，分母越大，整个复杂度项越小，上界越紧。这符合直觉：数据越多，模型越稳定，泛化能力估计越可靠。</li></ul></li><li><ul><li>*$\delta$ (置信度参数)**：$\delta$ 越小（例如从 0.05 减小到 0.01，表示我们希望有 99% 的把握），$\log \frac{4}{\delta}$ 越大，上界也越大。这是因为我们要求更高的置信度，就需要更宽松的上界。</li></ul></li></ul></li></ul><h3 id="4-泛化误差上界的作用与意义"><a href="#4-泛化误差上界的作用与意义" class="headerlink" title="4. 泛化误差上界的作用与意义"></a>4. 泛化误差上界的作用与意义</h3><ol><li><p><strong>解释结构风险最小化 (SRM) 原理</strong>：</p><ul><li>结构风险 $R_{srm}(f) &#x3D; R_{emp}(f) + \lambda J(f)$。</li><li>泛化误差上界公式 $R_{exp}(f) \le R_{emp}(f) + \Omega(N, d, \delta)$ 揭示了 SRM 的理论依据。</li><li>SRM 策略通过引入正则化项 $J(f)$ 来惩罚模型复杂度，这与泛化误差上界中的复杂度项 $\Omega$ 相呼应。两者都是为了在经验误差小和模型复杂度低之间寻找平衡，以使泛化误差（或其上界）最小。</li><li>$\lambda J(f)$ 可以看作是对复杂度项 $\Omega$ 的一种 <strong>代替</strong> 或 <strong>工程近似</strong>，因为计算真实的 VC 维通常非常困难。</li></ul></li><li><p><strong>指导模型选择</strong>：</p><ul><li>在模型选择时，我们不仅要考虑经验误差，还要考虑模型的复杂度。</li><li>泛化误差上界告诉我们，模型复杂度过高会导致上界增大，即使经验误差很小，也可能泛化很差（过拟合）。</li><li>这正是避免 <strong>过拟合</strong> 的理论依据。</li></ul></li><li><p><strong>理解样本数量的重要性</strong>：</p><ul><li>公式中 $N$ 在分母上，直观地表明了增加训练样本数量可以降低泛化误差上界，从而提高模型的泛化能力。</li></ul></li><li><p><strong>提供理论保证</strong>：</p><ul><li>泛化误差上界为统计学习算法的有效性提供了数学上的理论保证，说明了在一定条件下，我们学到的模型确实有能力推广到未知数据。</li></ul></li></ol><h3 id="5-泛化误差上界的局限性"><a href="#5-泛化误差上界的局限性" class="headerlink" title="5. 泛化误差上界的局限性"></a>5. 泛化误差上界的局限性</h3><ol><li><strong>通常比较宽松</strong>：导出的上界往往比实际的泛化误差大很多，因此在实际应用中，它不直接用于预测模型的实际性能，而更多用于理论分析。</li><li><strong>VC 维难以计算</strong>：对于许多复杂的模型（如神经网络），计算其精确的 VC 维是非常困难的。因此，这个上界在实践中难以直接应用。</li><li><strong>依赖于损失函数和模型类型</strong>：不同的损失函数（如 0-1 损失、平方损失）和模型类型（如线性模型、核方法）会有不同的上界形式。</li></ol><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>泛化误差上界是统计学习理论中一个深刻而重要的概念。它通过数学公式揭示了泛化误差与经验误差、模型复杂度、样本数量和置信度之间的关系。它为我们理解为何要控制模型复杂度、为何需要大量数据以及为何结构风险最小化有效提供了坚实的理论基础。虽然在实践中我们更依赖交叉验证和测试集来评估泛化能力，但泛化误差上界的思想仍然是指导我们设计和选择机器学习算法的重要理论武器。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一-统计学习方法概论&quot;&gt;&lt;a href=&quot;#一-统计学习方法概论&quot; class=&quot;headerlink&quot; title=&quot;一.  统计学习方法概论&quot;&gt;&lt;/a&gt;一.  &lt;strong&gt;统计学习方法概论&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;​         主要是对统计学</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>有关c语言输入缓冲区的基础问题</title>
    <link href="http://rainemotion.github.io/2024/04/23/c%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%BE%93%E5%85%A5%E7%BC%93%E5%86%B2%E5%8C%BA/"/>
    <id>http://rainemotion.github.io/2024/04/23/c%E8%AF%AD%E8%A8%80%E4%B9%8B%E8%BE%93%E5%85%A5%E7%BC%93%E5%86%B2%E5%8C%BA/</id>
    <published>2024-04-23T14:21:32.231Z</published>
    <updated>2024-04-24T15:50:49.935Z</updated>
    
    <content type="html"><![CDATA[<h1 id="缓冲区是什么"><a href="#缓冲区是什么" class="headerlink" title="缓冲区是什么"></a>缓冲区是什么</h1><p>​        <strong>缓冲区</strong>（Buffer)是内存空间的一部分。也就是说，在内存中预留了一定的存储空间，用来暂时保存输入或输出的数据，这部分预留的空间就叫做缓冲区。缓冲区根据其对应的是输入设备还是输出设备，分为<em><strong>输入缓冲区</strong></em>和<em><strong>输出缓冲区</strong></em>。</p><p><strong>输入缓冲区及例子</strong></p><p>​        <strong>输入缓冲区</strong>是我们经常忽视而导致出错的知识点。scanf和getchar等输入函数存在输入缓存用户从键盘输入内容,并按下<strong>回车键</strong>(即换行’\n’)确认,之后,输入的字符将进入输入缓冲区，然后输入函数便从输入缓冲区获取字符，并删除缓存区已获取的字符。</p><p>​    <strong>下面举几个例子来具体分析一下</strong>,</p><h2 id="scanf"><a href="#scanf" class="headerlink" title="scanf"></a>scanf</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> a, b;</span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%c&quot;</span>, &amp;a);</span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%c&quot;</span>, &amp;b);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%c %c&quot;</span>, a, b);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当我们输入a和\n时，会出现：</p><p><img src="/../images/20240423202241720.png"></p><p>当我们输入a和回车键(即’\n’时)，输入缓存区上此时有两个字符，分别是a和\n。于是，第一个scanf将a从输入缓冲区取出并打印在终端上，scanf()作单字符输入时规定只接收一个字符，<strong>但它却把回车符也作为字符对待的</strong>。于是第二个scanf则直接将输入缓冲区还存在的\n取出并打印在终端显示屏上，就有了如图所示的结果。</p><p><strong>正确做法如下：</strong></p><p><img src="/../images/20240423203622053.png"></p><p>有了scanf(“ %c”,&amp;c)这个空格（换成\n或者\t也可以），<strong>这样就把缓冲区中的回车当成第一个字符，读取后丢掉</strong>。</p><h2 id="getchar"><a href="#getchar" class="headerlink" title="getchar"></a>getchar</h2><h3 id="getchar的用法"><a href="#getchar的用法" class="headerlink" title="getchar的用法"></a><strong>getchar的用法</strong></h3><p>getchar()函数的作用是从stdin (标准输入——键盘）获取字符，他的返回值类型是int，因为字符在存储时是以阿斯克码值存储的，所以getchar()读取的是<strong>一个</strong>字符而返回的却是<strong>整形</strong>，返回整形是返回了他的<strong>阿斯克码值</strong>，当getchar()读取错误的时候会返回EOF，EOF的含义就是end of file，是文件的结束标志。我们可以在编译器中转到定义发现EOF就是-1，也符合getchar()函数的返回值类型int。</p><h3 id="getchar例子"><a href="#getchar例子" class="headerlink" title="getchar例子"></a><strong>getchar例子</strong></h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> ch;</span><br><span class="line"><span class="keyword">while</span> ((ch = getchar()) != EOF)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">putchar</span>(ch);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;&#125;</span><br></pre></td></tr></table></figure><p><img src="/../images/20240423205647993.png"></p><p>将getchar()函数放在while循环当中作为条件，就可以实现连续输入和打印。用户键盘输入进入判断，如果getchar()正常获取字符那么我们进入循环打印字符，再次输入，如果getchar()获取字符异常返回EOF，那么就跳出循环。前面已经说过，getchar读取缓冲区内的<strong>一个</strong>字符，所以，每次循环读取缓冲区中的一个字符，直到缓冲区内字符都被读取完成后，继续在键盘上输入字符并存在输入缓冲区里，之后继续循环，每次读取缓冲区的一个字符，直到读取错误(即返回EOF)。</p><h1 id="如何清理缓冲区的字符"><a href="#如何清理缓冲区的字符" class="headerlink" title="如何清理缓冲区的字符"></a>如何清理缓冲区的字符</h1><h2 id="用rewind函数刷新缓冲区"><a href="#用rewind函数刷新缓冲区" class="headerlink" title="用rewind函数刷新缓冲区"></a>用rewind函数刷新缓冲区</h2><blockquote><p>用rewind(stdin);<strong>rewind函数是把指定流的读写指针重新指向开头。</strong></p></blockquote><p><img src="/../images/20240423211826508.png"></p><h2 id="用getchar-来清理缓冲区"><a href="#用getchar-来清理缓冲区" class="headerlink" title="用getchar();来清理缓冲区"></a>用getchar();来清理缓冲区</h2><blockquote><p>用getchar()函数，提前将缓冲区中的<code>\n</code>取走，就可达到我们想要的目的，这样的方法叫做清理缓冲区</p></blockquote><p><img src="/../images/20240423212422895.png"></p><p>如图我们将getchar()放入while循环当中就可以实现缓冲区中多个字符的清除，当scanf进入缓冲区获取字符时会拿取asdf，遇到空格scanf停止获取，之后进入循环getchar()进入缓冲区读取字符，只要没有读到\n循环就继续循环，遍历完缓冲区字符后，最后获取\n跳出循环，进行后一步操作。</p><h1 id="gets-与fgets"><a href="#gets-与fgets" class="headerlink" title="gets()与fgets()"></a>gets()与fgets()</h1><h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2><p>1、虽然用 gets() 时有空格也可以直接输入，但是 gets() 有一个非常大的缺陷，即它不检查预留存储区是否能够容纳实际输入的数据，换句话说，如果输入的字符数目大于数组的长度，gets 无法检测到这个问题，就会发生内存越界，一般用fgets().</p><p>2、 fgets() 和 gets() 一样，最后的回车都会从缓冲区中取出来。<strong>只不过 gets() 是取出来丢掉，而 fgets() 是取出来自己留着</strong>。但总之缓冲区中是没有回车了！所以与 gets() 一样，在使用 fgets() 的时候，如果后面要从键盘给字符变量赋值，那么同样<strong>不需要清空缓冲区</strong>。</p><blockquote><p> <strong>fgets(str, 7, stdin);  从输入流stdin即输入缓冲区中读取7个字符到字符数组str中</strong></p></blockquote><p>3、所以假如你定义的字符数组长度为 n，那么 fgets() 中的 size 就指定为 n–1，留一个给 ‘\0’ 就行了。但是需要注意的是，如果输入的字符串长度没有超过 n–1，那么系统会将最后输入的换行符 ‘\n’ 保存进来，<strong>保存的位置是紧跟输入的字符</strong>，然后剩余的空间都用 <strong>‘\0’ 填充</strong>。所以此时输出该字符串时 printf 中就不需要加换行符 ‘\n’ 了，因为字符串中已经有了。</p><h2 id="有关缓冲区的例子："><a href="#有关缓冲区的例子：" class="headerlink" title="有关缓冲区的例子："></a>有关缓冲区的例子：</h2><h3 id="用fgets"><a href="#用fgets" class="headerlink" title="用fgets()"></a>用fgets()</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="type">char</span> str[<span class="number">30</span>];</span><br><span class="line"> <span class="type">char</span> ch;</span><br><span class="line"> <span class="built_in">printf</span>(<span class="string">&quot;请输入字符串：&quot;</span>);</span><br><span class="line"> fgets(str, <span class="number">29</span>, <span class="built_in">stdin</span>);</span><br><span class="line"> <span class="built_in">printf</span>(<span class="string">&quot;%s&quot;</span>, str);  <span class="comment">//后面不要加&#x27;\n&#x27;</span></span><br><span class="line"> <span class="built_in">scanf</span>(<span class="string">&quot;%c&quot;</span>, &amp;ch);</span><br><span class="line"> <span class="built_in">printf</span>(<span class="string">&quot;ch = %c\n&quot;</span>, ch);</span><br><span class="line"> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>输出结果是：</strong><br>请输入字符串：i love you<br>i love you<br>Y<br>ch &#x3D; Y</p><h3 id="用gets"><a href="#用gets" class="headerlink" title="用gets()"></a>用gets()</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="type">char</span> str[<span class="number">30</span>];</span><br><span class="line"><span class="type">char</span> ch;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;请输入字符串：&quot;</span>);</span><br><span class="line"><span class="built_in">gets</span>(str);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%s&quot;</span>, str);  <span class="comment">//后面不要加&#x27;\n&#x27;</span></span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%c&quot;</span>, &amp;ch);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;ch = %c\n&quot;</span>, ch);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/../images/20240423221106147.png"></p><p>输入同样的数据，结果却不一样，如图所示，再一次说明了fgets() 和 gets() 一样，最后的回车都会从缓冲区中取出来。只不过 gets() 是取出来<strong>丢掉</strong>，而 fgets() 是取出来<strong>自己留着</strong>。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><blockquote><p>1、rewind通过<strong>刷新缓冲区</strong>(相当于能瞬间将缓冲区还存在的所有字符清除)。</p><p>2、getchar则只能每次读取缓冲区的<strong>一个字符</strong>来清理缓冲区，一般需要通过<strong>循环</strong>来清理缓冲区，使用**while((ch &#x3D; getchar()) !&#x3D; ‘\n’ &amp;&amp; ch !&#x3D; EOF)**（万能代码）。</p><p>3、scanf遇到<strong>空格</strong>和<strong>\n</strong>会停止从缓冲区读取字符。</p><p>4、getchar()函数的作用是从标准输入键盘中<strong>读取一个字符</strong>。</p><p>5、getchar()的返回值类型为<strong>整形</strong>，返回的是读取到字符的<strong>阿斯克码值</strong>。</p><p>6、当getchar()函数读取失败时，<strong>返回EOF</strong>文件的结束标志。</p><p>7、fgets(str, 7, stdin);  表示从输入流stdin即<strong>输入缓冲区</strong>中读取7个字符到字符数组str中。</p><p>8、fgets() 和 gets() 一样，最后的回车都会从缓冲区中取出来。只不过 gets() 是取出来<strong>丢掉</strong>，而 fgets() 是取出来<strong>自己留着</strong>。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;缓冲区是什么&quot;&gt;&lt;a href=&quot;#缓冲区是什么&quot; class=&quot;headerlink&quot; title=&quot;缓冲区是什么&quot;&gt;&lt;/a&gt;缓冲区是什么&lt;/h1&gt;&lt;p&gt;​        &lt;strong&gt;缓冲区&lt;/strong&gt;（Buffer)是内存空间的一部分。也就是说，在内</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>伤心的一天</title>
    <link href="http://rainemotion.github.io/2024/04/22/Extremly%20depressed/"/>
    <id>http://rainemotion.github.io/2024/04/22/Extremly%20depressed/</id>
    <published>2024-04-22T11:39:09.047Z</published>
    <updated>2024-04-23T15:29:17.696Z</updated>
    
    <content type="html"><![CDATA[<p><strong>郁闷</strong>！😥(´。＿。｀)</p><p><strong>不解</strong>！😭::&gt;_&lt;::</p><p><strong>伤心</strong>！🥲ಥ_ಥ</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;郁闷&lt;/strong&gt;！😥(´。＿。｀)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;不解&lt;/strong&gt;！😭::&amp;gt;_&amp;lt;::&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;伤心&lt;/strong&gt;！🥲ಥ_ಥ&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>初出茅庐</title>
    <link href="http://rainemotion.github.io/2023/11/12/hello-world/"/>
    <id>http://rainemotion.github.io/2023/11/12/hello-world/</id>
    <published>2023-11-12T10:08:38.307Z</published>
    <updated>2024-04-22T12:22:23.688Z</updated>
    
    <content type="html"><![CDATA[<p>博客初建，尚未完善。作为第一篇文章，就以“初出茅庐”为题，浅谈这几个月在学校的感受。</p><p>-<em><strong>生活</strong></em></p><p>还行，就是宿舍有点low.</p><p>-<em><strong>学习</strong></em></p><p>一般般，就是需要学的确实太多了，Math or C,that is the question.</p><p>-<em><strong>游戏</strong></em></p><p>针不戳，从进校前100个小时的打劫，到如今的400多个小时，爽！</p><p>-<em><strong>总结</strong></em></p><p>“遇事不决，可问春风”，希望我能在学习和娱乐中不负青春，奋斗前行，干就完了！    </p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;博客初建，尚未完善。作为第一篇文章，就以“初出茅庐”为题，浅谈这几个月在学校的感受。	&lt;/p&gt;
&lt;p&gt;-&lt;em&gt;&lt;strong&gt;生活&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;还行，就是宿舍有点low.	&lt;/p&gt;
&lt;p&gt;-&lt;em&gt;&lt;strong&gt;学习&lt;/strong&gt;&lt;/e</summary>
      
    
    
    
    
  </entry>
  
</feed>
